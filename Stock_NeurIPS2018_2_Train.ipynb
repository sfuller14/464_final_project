{"cells":[{"cell_type":"markdown","metadata":{"id":"QMjwq6pS-kFz"},"source":["# Stock NeurIPS2018 Part 2. Train\n","This series is a reproduction of *the process in the paper Practical Deep Reinforcement Learning Approach for Stock Trading*.\n","\n","This is the second part of the NeurIPS2018 series, introducing how to use FinRL to make data into the gym form environment, and train DRL agents on it.\n","\n","Other demos can be found at the repo of [FinRL-Tutorials]((https://github.com/AI4Finance-Foundation/FinRL-Tutorials))."]},{"cell_type":"markdown","metadata":{"id":"gT-zXutMgqOS"},"source":["# Part 1. Install Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17755,"status":"ok","timestamp":1691998457980,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"D0vEcPxSJ8hI","outputId":"8cf3bff8-77fa-4ebc-d1dc-51cf97306758"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# %cd 'drive/Othercomputers/My Mac/Code/msds-local/464/Final_Project/FinRL'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51824,"status":"ok","timestamp":1691998513932,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"mP84gNpu9yt9","outputId":"d701df0e-d4c4-41ae-8a14-0d7c0e7ba319"},"outputs":[],"source":["# !pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46638,"status":"ok","timestamp":1691998572918,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"kkv0wzbt9xpf","outputId":"35d093f4-cf5d-410f-c33a-d955c1c288b8"},"outputs":[],"source":["## failure on box2d-py...\n","# !pip install pandas\n","# !pip install yfinance\n","# !pip install gymnasium\n","# !pip install matplotlib\n","# !pip install stable_baselines3\n","# !pip install stockstats\n","# !pip install alpaca_trade_api\n","# !pip install exchange_calendars\n","# !pip install wrds\n","# !pip install tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_1B2WN7p98mM"},"outputs":[],"source":["## restart if prompted then\n","# %cd 'drive/Othercomputers/My Mac/Code/msds-local/464/Final_Project/FinRL'"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":16274,"status":"ok","timestamp":1691998596712,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"xt1317y2ixSS"},"outputs":[],"source":["import pandas as pd\n","from stable_baselines3.common.logger import configure\n","\n","from finrl.agents.stablebaselines3.models import DRLAgent\n","from finrl.config import INDICATORS, TRAINED_MODEL_DIR, RESULTS_DIR\n","from finrl.main import check_and_make_directories\n","from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n","\n","check_and_make_directories([TRAINED_MODEL_DIR])"]},{"cell_type":"markdown","metadata":{"id":"aWrSrQv3i0Ng"},"source":["# Part 2. Build A Market Environment in OpenAI Gym-style"]},{"cell_type":"markdown","metadata":{"id":"wiHhM2U-XBMZ"},"source":["![rl_diagram_transparent_bg.png](data:image/png;base64,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)"]},{"cell_type":"markdown","metadata":{"id":"LeneTRdyZDvy"},"source":["The core element in reinforcement learning are **agent** and **environment**. You can understand RL as the following process:\n","\n","The agent is active in a world, which is the environment. It observe its current condition as a **state**, and is allowed to do certain **actions**. After the agent execute an action, it will arrive at a new state. At the same time, the environment will have feedback to the agent called **reward**, a numerical signal that tells how good or bad the new state is. As the figure above, agent and environment will keep doing this interaction.\n","\n","The goal of agent is to get as much cumulative reward as possible. Reinforcement learning is the method that agent learns to improve its behavior and achieve that goal."]},{"cell_type":"markdown","metadata":{"id":"w3H88JXkI93v"},"source":["To achieve this in Python, we follow the OpenAI gym style to build the stock data into environment.\n","\n","state-action-reward are specified as follows:\n","\n","* **State s**: The state space represents an agent's perception of the market environment. Just like a human trader analyzing various information, here our agent passively observes the price data and technical indicators based on the past data. It will learn by interacting with the market environment (usually by replaying historical data).\n","\n","* **Action a**: The action space includes allowed actions that an agent can take at each state. For example, a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n","selling, holding, and buying. When an action operates multiple shares, a ∈{−k, ..., −1, 0, 1, ..., k}, e.g.. \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n","\n","* **Reward function r(s, a, s′)**: Reward is an incentive for an agent to learn a better policy. For example, it can be the change of the portfolio value when taking a at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio values at state s′ and s, respectively\n","\n","\n","**Market environment**: 30 constituent stocks of Dow Jones Industrial Average (DJIA) index. Accessed at the starting date of the testing period."]},{"cell_type":"markdown","metadata":{"id":"SKyZejI0fmp1"},"source":["## Read data\n","\n","We first read the .csv file of our training data into dataframe."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1370,"status":"ok","timestamp":1691998601433,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"mFCP1YEhi6oi"},"outputs":[],"source":["train = pd.read_csv('train_data.csv')\n","\n","# If you are not using the data generated from part 1 of this tutorial, make sure\n","# it has the columns and index in the form that could be make into the environment.\n","# Then you can comment and skip the following two lines.\n","train = train.set_index(train.columns[0])\n","train.index.names = ['']"]},{"cell_type":"markdown","metadata":{"id":"Yw95ZMicgEyi"},"source":["## Construct the environment"]},{"cell_type":"markdown","metadata":{"id":"5WZ6-9q2gq9S"},"source":["Calculate and specify the parameters we need for constructing the environment."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176,"status":"ok","timestamp":1691998603996,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"7T3DZPoaIm8k","outputId":"fcac7881-52ee-4293-df65-8b3e1c0040de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Stock Dimension: 29, State Space: 291\n"]}],"source":["stock_dimension = len(train.tic.unique())\n","state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n","print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":171,"status":"ok","timestamp":1691998605973,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"WsOLoeNcJF8Q"},"outputs":[],"source":["buy_cost_list = sell_cost_list = [0.001] * stock_dimension\n","num_stock_shares = [0] * stock_dimension\n","\n","env_kwargs = {\n","    \"hmax\": 100,\n","    \"initial_amount\": 1000000,\n","    \"num_stock_shares\": num_stock_shares,\n","    \"buy_cost_pct\": buy_cost_list,\n","    \"sell_cost_pct\": sell_cost_list,\n","    \"state_space\": state_space,\n","    \"stock_dim\": stock_dimension,\n","    \"tech_indicator_list\": INDICATORS,\n","    \"action_space\": stock_dimension,\n","    \"reward_scaling\": 1e-4\n","}\n","\n","\n","e_train_gym = StockTradingEnv(df = train, **env_kwargs)"]},{"cell_type":"markdown","metadata":{"id":"7We-q73jjaFQ"},"source":["## Environment for training"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1691998609440,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"aS-SHiGRJK-4","outputId":"2be047ba-04e8-45ce-ea13-108c5919dfd3"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"]}],"source":["env_train, _ = e_train_gym.get_sb_env()\n","print(type(env_train))"]},{"cell_type":"markdown","metadata":{"id":"HMNR5nHjh1iz"},"source":["# Part 3: Train DRL Agents\n","* Here, the DRL algorithms are from **[Stable Baselines 3](https://stable-baselines3.readthedocs.io/en/master/)**. It's a library that implemented popular DRL algorithms using pytorch, succeeding to its old version: Stable Baselines.\n","* Users are also encouraged to try **[ElegantRL](https://github.com/AI4Finance-Foundation/ElegantRL)** and **[Ray RLlib](https://github.com/ray-project/ray)**."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":199,"status":"ok","timestamp":1691998614221,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"364PsqckttcQ"},"outputs":[],"source":["agent = DRLAgent(env = env_train)\n","\n","# Set the corresponding values to 'True' for the algorithms that you want to use\n","if_using_a2c = True\n","if_using_ddpg = True\n","if_using_ppo = True\n","if_using_td3 = True\n","if_using_sac = True"]},{"cell_type":"markdown","metadata":{"id":"YDmqOyF9h1iz"},"source":["## Agent Training: 5 algorithms (A2C, DDPG, PPO, TD3, SAC)\n"]},{"cell_type":"markdown","metadata":{"id":"uijiWgkuh1jB"},"source":["### Agent 1: A2C\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18668,"status":"ok","timestamp":1691997260857,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"GUCnkn-HIbmj","outputId":"a8399b0a-83d6-461b-9cff-67de52213b74"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n","Using cuda device\n","Logging to results/a2c\n"]}],"source":["agent = DRLAgent(env = env_train)\n","model_a2c = agent.get_model(\"a2c\")\n","\n","if if_using_a2c:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + '/a2c'\n","  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_a2c.set_logger(new_logger_a2c)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":510461,"status":"ok","timestamp":1691997773192,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"0GVpkWGqH4-D","outputId":"b97526b0-69a5-4c49-9a69-42b1cfc7c66a"},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------------------------------\n","| time/                 |             |\n","|    fps                | 59          |\n","|    iterations         | 100         |\n","|    time_elapsed       | 8           |\n","|    total_timesteps    | 500         |\n","| train/                |             |\n","|    entropy_loss       | -41.3       |\n","|    explained_variance | 0.453       |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 99          |\n","|    policy_loss        | 18.2        |\n","|    reward             | -0.18390413 |\n","|    std                | 1           |\n","|    value_loss         | 0.684       |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 73         |\n","|    iterations         | 200        |\n","|    time_elapsed       | 13         |\n","|    total_timesteps    | 1000       |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 199        |\n","|    policy_loss        | -56.8      |\n","|    reward             | -1.8611349 |\n","|    std                | 1.01       |\n","|    value_loss         | 2.32       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 80        |\n","|    iterations         | 300       |\n","|    time_elapsed       | 18        |\n","|    total_timesteps    | 1500      |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | -0.00344  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 299       |\n","|    policy_loss        | -294      |\n","|    reward             | 3.1081812 |\n","|    std                | 1.01      |\n","|    value_loss         | 62.2      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 84       |\n","|    iterations         | 400      |\n","|    time_elapsed       | 23       |\n","|    total_timesteps    | 2000     |\n","| train/                |          |\n","|    entropy_loss       | -41.3    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 399      |\n","|    policy_loss        | -100     |\n","|    reward             | 2.016273 |\n","|    std                | 1.01     |\n","|    value_loss         | 5.92     |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 87        |\n","|    iterations         | 500       |\n","|    time_elapsed       | 28        |\n","|    total_timesteps    | 2500      |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 499       |\n","|    policy_loss        | 437       |\n","|    reward             | -9.566339 |\n","|    std                | 1.01      |\n","|    value_loss         | 130       |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 88         |\n","|    iterations         | 600        |\n","|    time_elapsed       | 33         |\n","|    total_timesteps    | 3000       |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0.227      |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 599        |\n","|    policy_loss        | 146        |\n","|    reward             | -0.7343847 |\n","|    std                | 1.01       |\n","|    value_loss         | 14.8       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 90         |\n","|    iterations         | 700        |\n","|    time_elapsed       | 38         |\n","|    total_timesteps    | 3500       |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 699        |\n","|    policy_loss        | -172       |\n","|    reward             | -6.3908243 |\n","|    std                | 1.01       |\n","|    value_loss         | 20.9       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 91         |\n","|    iterations         | 800        |\n","|    time_elapsed       | 43         |\n","|    total_timesteps    | 4000       |\n","| train/                |            |\n","|    entropy_loss       | -41.3      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 799        |\n","|    policy_loss        | -28.6      |\n","|    reward             | -2.0454543 |\n","|    std                | 1.01       |\n","|    value_loss         | 1.62       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 92         |\n","|    iterations         | 900        |\n","|    time_elapsed       | 48         |\n","|    total_timesteps    | 4500       |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | 0.0928     |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 899        |\n","|    policy_loss        | 148        |\n","|    reward             | -1.6625124 |\n","|    std                | 1.01       |\n","|    value_loss         | 14.2       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 92         |\n","|    iterations         | 1000       |\n","|    time_elapsed       | 53         |\n","|    total_timesteps    | 5000       |\n","| train/                |            |\n","|    entropy_loss       | -41.4      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 999        |\n","|    policy_loss        | 19.4       |\n","|    reward             | -2.3052192 |\n","|    std                | 1.01       |\n","|    value_loss         | 1.1        |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 93        |\n","|    iterations         | 1100      |\n","|    time_elapsed       | 58        |\n","|    total_timesteps    | 5500      |\n","| train/                |           |\n","|    entropy_loss       | -41.3     |\n","|    explained_variance | -0.000731 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1099      |\n","|    policy_loss        | -282      |\n","|    reward             | 0.7917788 |\n","|    std                | 1.01      |\n","|    value_loss         | 48.6      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 93          |\n","|    iterations         | 1200        |\n","|    time_elapsed       | 63          |\n","|    total_timesteps    | 6000        |\n","| train/                |             |\n","|    entropy_loss       | -41.3       |\n","|    explained_variance | -0.0285     |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 1199        |\n","|    policy_loss        | -167        |\n","|    reward             | -0.33230415 |\n","|    std                | 1.01        |\n","|    value_loss         | 22.2        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 93        |\n","|    iterations         | 1300      |\n","|    time_elapsed       | 69        |\n","|    total_timesteps    | 6500      |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | -0.0309   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1299      |\n","|    policy_loss        | 175       |\n","|    reward             | -5.642178 |\n","|    std                | 1.01      |\n","|    value_loss         | 35.4      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 94        |\n","|    iterations         | 1400      |\n","|    time_elapsed       | 74        |\n","|    total_timesteps    | 7000      |\n","| train/                |           |\n","|    entropy_loss       | -41.4     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1399      |\n","|    policy_loss        | -62.1     |\n","|    reward             | 2.4323335 |\n","|    std                | 1.01      |\n","|    value_loss         | 9.69      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 94       |\n","|    iterations         | 1500     |\n","|    time_elapsed       | 79       |\n","|    total_timesteps    | 7500     |\n","| train/                |          |\n","|    entropy_loss       | -41.4    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 1499     |\n","|    policy_loss        | 127      |\n","|    reward             | 2.44823  |\n","|    std                | 1.01     |\n","|    value_loss         | 17.6     |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 94        |\n","|    iterations         | 1600      |\n","|    time_elapsed       | 84        |\n","|    total_timesteps    | 8000      |\n","| train/                |           |\n","|    entropy_loss       | -41.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1599      |\n","|    policy_loss        | -57.6     |\n","|    reward             | 2.0646086 |\n","|    std                | 1.01      |\n","|    value_loss         | 8.99      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 95        |\n","|    iterations         | 1700      |\n","|    time_elapsed       | 89        |\n","|    total_timesteps    | 8500      |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 1699      |\n","|    policy_loss        | -156      |\n","|    reward             | 15.964571 |\n","|    std                | 1.02      |\n","|    value_loss         | 46.8      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 95       |\n","|    iterations         | 1800     |\n","|    time_elapsed       | 94       |\n","|    total_timesteps    | 9000     |\n","| train/                |          |\n","|    entropy_loss       | -41.6    |\n","|    explained_variance | 1.19e-07 |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 1799     |\n","|    policy_loss        | 59.1     |\n","|    reward             | 4.173474 |\n","|    std                | 1.02     |\n","|    value_loss         | 2.38     |\n","------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 95         |\n","|    iterations         | 1900       |\n","|    time_elapsed       | 99         |\n","|    total_timesteps    | 9500       |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 1899       |\n","|    policy_loss        | -70.6      |\n","|    reward             | -0.7894686 |\n","|    std                | 1.02       |\n","|    value_loss         | 4.52       |\n","--------------------------------------\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 95           |\n","|    iterations         | 2000         |\n","|    time_elapsed       | 104          |\n","|    total_timesteps    | 10000        |\n","| train/                |              |\n","|    entropy_loss       | -41.6        |\n","|    explained_variance | 0            |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 1999         |\n","|    policy_loss        | -93          |\n","|    reward             | -0.021824883 |\n","|    std                | 1.02         |\n","|    value_loss         | 6.22         |\n","----------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 95        |\n","|    iterations         | 2100      |\n","|    time_elapsed       | 109       |\n","|    total_timesteps    | 10500     |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | 0.0194    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2099      |\n","|    policy_loss        | 122       |\n","|    reward             | 1.9878135 |\n","|    std                | 1.02      |\n","|    value_loss         | 17.9      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 96        |\n","|    iterations         | 2200      |\n","|    time_elapsed       | 114       |\n","|    total_timesteps    | 11000     |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2199      |\n","|    policy_loss        | 101       |\n","|    reward             | -9.825861 |\n","|    std                | 1.02      |\n","|    value_loss         | 8.63      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 96        |\n","|    iterations         | 2300      |\n","|    time_elapsed       | 119       |\n","|    total_timesteps    | 11500     |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2299      |\n","|    policy_loss        | -3.23e+03 |\n","|    reward             | 16.005585 |\n","|    std                | 1.02      |\n","|    value_loss         | 5.53e+03  |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 96        |\n","|    iterations         | 2400      |\n","|    time_elapsed       | 124       |\n","|    total_timesteps    | 12000     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2399      |\n","|    policy_loss        | 61.3      |\n","|    reward             | 1.4592744 |\n","|    std                | 1.02      |\n","|    value_loss         | 7         |\n","-------------------------------------\n","-----------------------------------------\n","| time/                 |               |\n","|    fps                | 96            |\n","|    iterations         | 2500          |\n","|    time_elapsed       | 129           |\n","|    total_timesteps    | 12500         |\n","| train/                |               |\n","|    entropy_loss       | -41.7         |\n","|    explained_variance | 0             |\n","|    learning_rate      | 0.0007        |\n","|    n_updates          | 2499          |\n","|    policy_loss        | -66.7         |\n","|    reward             | -0.0038606508 |\n","|    std                | 1.02          |\n","|    value_loss         | 2.47          |\n","-----------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 96         |\n","|    iterations         | 2600       |\n","|    time_elapsed       | 134        |\n","|    total_timesteps    | 13000      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 2599       |\n","|    policy_loss        | -20        |\n","|    reward             | 0.69583625 |\n","|    std                | 1.02       |\n","|    value_loss         | 0.468      |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 96        |\n","|    iterations         | 2700      |\n","|    time_elapsed       | 139       |\n","|    total_timesteps    | 13500     |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2699      |\n","|    policy_loss        | -68.3     |\n","|    reward             | 1.6036346 |\n","|    std                | 1.02      |\n","|    value_loss         | 3.88      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 96        |\n","|    iterations         | 2800      |\n","|    time_elapsed       | 145       |\n","|    total_timesteps    | 14000     |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2799      |\n","|    policy_loss        | 53.1      |\n","|    reward             | 1.997307  |\n","|    std                | 1.02      |\n","|    value_loss         | 5.77      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 96       |\n","|    iterations         | 2900     |\n","|    time_elapsed       | 150      |\n","|    total_timesteps    | 14500    |\n","| train/                |          |\n","|    entropy_loss       | -41.6    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 2899     |\n","|    policy_loss        | -169     |\n","|    reward             | 4.194698 |\n","|    std                | 1.02     |\n","|    value_loss         | 16.4     |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 96        |\n","|    iterations         | 3000      |\n","|    time_elapsed       | 155       |\n","|    total_timesteps    | 15000     |\n","| train/                |           |\n","|    entropy_loss       | -41.6     |\n","|    explained_variance | 0.000452  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 2999      |\n","|    policy_loss        | 29.7      |\n","|    reward             | 1.9914942 |\n","|    std                | 1.02      |\n","|    value_loss         | 1.65      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 96         |\n","|    iterations         | 3100       |\n","|    time_elapsed       | 160        |\n","|    total_timesteps    | 15500      |\n","| train/                |            |\n","|    entropy_loss       | -41.6      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3099       |\n","|    policy_loss        | 84         |\n","|    reward             | -0.6467693 |\n","|    std                | 1.02       |\n","|    value_loss         | 6.9        |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 96         |\n","|    iterations         | 3200       |\n","|    time_elapsed       | 165        |\n","|    total_timesteps    | 16000      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | -0.0491    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3199       |\n","|    policy_loss        | -135       |\n","|    reward             | -2.2685707 |\n","|    std                | 1.02       |\n","|    value_loss         | 41.2       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 96        |\n","|    iterations         | 3300      |\n","|    time_elapsed       | 170       |\n","|    total_timesteps    | 16500     |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3299      |\n","|    policy_loss        | 22        |\n","|    reward             | 1.5031915 |\n","|    std                | 1.02      |\n","|    value_loss         | 1.28      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 96       |\n","|    iterations         | 3400     |\n","|    time_elapsed       | 175      |\n","|    total_timesteps    | 17000    |\n","| train/                |          |\n","|    entropy_loss       | -41.7    |\n","|    explained_variance | 0.0347   |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 3399     |\n","|    policy_loss        | 204      |\n","|    reward             | 4.110051 |\n","|    std                | 1.02     |\n","|    value_loss         | 38.3     |\n","------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 96         |\n","|    iterations         | 3500       |\n","|    time_elapsed       | 180        |\n","|    total_timesteps    | 17500      |\n","| train/                |            |\n","|    entropy_loss       | -41.7      |\n","|    explained_variance | 0.00532    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3499       |\n","|    policy_loss        | 105        |\n","|    reward             | -0.5218197 |\n","|    std                | 1.02       |\n","|    value_loss         | 10.8       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 3600      |\n","|    time_elapsed       | 185       |\n","|    total_timesteps    | 18000     |\n","| train/                |           |\n","|    entropy_loss       | -41.7     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3599      |\n","|    policy_loss        | -84.6     |\n","|    reward             | 1.0813268 |\n","|    std                | 1.02      |\n","|    value_loss         | 6.71      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 97          |\n","|    iterations         | 3700        |\n","|    time_elapsed       | 190         |\n","|    total_timesteps    | 18500       |\n","| train/                |             |\n","|    entropy_loss       | -41.8       |\n","|    explained_variance | 0.0194      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 3699        |\n","|    policy_loss        | 145         |\n","|    reward             | -0.30414632 |\n","|    std                | 1.02        |\n","|    value_loss         | 15.5        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 3800       |\n","|    time_elapsed       | 195        |\n","|    total_timesteps    | 19000      |\n","| train/                |            |\n","|    entropy_loss       | -41.8      |\n","|    explained_variance | -0.0299    |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 3799       |\n","|    policy_loss        | 52.3       |\n","|    reward             | -0.6126412 |\n","|    std                | 1.02       |\n","|    value_loss         | 2.63       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 3900      |\n","|    time_elapsed       | 200       |\n","|    total_timesteps    | 19500     |\n","| train/                |           |\n","|    entropy_loss       | -41.8     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 3899      |\n","|    policy_loss        | -250      |\n","|    reward             | 1.9764712 |\n","|    std                | 1.02      |\n","|    value_loss         | 44.9      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 97       |\n","|    iterations         | 4000     |\n","|    time_elapsed       | 205      |\n","|    total_timesteps    | 20000    |\n","| train/                |          |\n","|    entropy_loss       | -41.7    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 3999     |\n","|    policy_loss        | -162     |\n","|    reward             | 5.69516  |\n","|    std                | 1.02     |\n","|    value_loss         | 15.4     |\n","------------------------------------\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 97           |\n","|    iterations         | 4100         |\n","|    time_elapsed       | 210          |\n","|    total_timesteps    | 20500        |\n","| train/                |              |\n","|    entropy_loss       | -41.7        |\n","|    explained_variance | 1.19e-07     |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 4099         |\n","|    policy_loss        | 4.84         |\n","|    reward             | -0.073355064 |\n","|    std                | 1.02         |\n","|    value_loss         | 2.68         |\n","----------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 97       |\n","|    iterations         | 4200     |\n","|    time_elapsed       | 215      |\n","|    total_timesteps    | 21000    |\n","| train/                |          |\n","|    entropy_loss       | -41.8    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 4199     |\n","|    policy_loss        | -102     |\n","|    reward             | 2.312689 |\n","|    std                | 1.02     |\n","|    value_loss         | 10.3     |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 4300      |\n","|    time_elapsed       | 221       |\n","|    total_timesteps    | 21500     |\n","| train/                |           |\n","|    entropy_loss       | -41.8     |\n","|    explained_variance | -0.161    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 4299      |\n","|    policy_loss        | -102      |\n","|    reward             | 5.0280285 |\n","|    std                | 1.02      |\n","|    value_loss         | 7.76      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 97       |\n","|    iterations         | 4400     |\n","|    time_elapsed       | 226      |\n","|    total_timesteps    | 22000    |\n","| train/                |          |\n","|    entropy_loss       | -41.9    |\n","|    explained_variance | 1.19e-07 |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 4399     |\n","|    policy_loss        | -31.9    |\n","|    reward             | 5.04948  |\n","|    std                | 1.03     |\n","|    value_loss         | 29       |\n","------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 4500       |\n","|    time_elapsed       | 231        |\n","|    total_timesteps    | 22500      |\n","| train/                |            |\n","|    entropy_loss       | -41.9      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4499       |\n","|    policy_loss        | 496        |\n","|    reward             | -4.8031726 |\n","|    std                | 1.03       |\n","|    value_loss         | 146        |\n","--------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 97       |\n","|    iterations         | 4600     |\n","|    time_elapsed       | 236      |\n","|    total_timesteps    | 23000    |\n","| train/                |          |\n","|    entropy_loss       | -41.9    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 4599     |\n","|    policy_loss        | 483      |\n","|    reward             | 3.354638 |\n","|    std                | 1.03     |\n","|    value_loss         | 160      |\n","------------------------------------\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 97           |\n","|    iterations         | 4700         |\n","|    time_elapsed       | 241          |\n","|    total_timesteps    | 23500        |\n","| train/                |              |\n","|    entropy_loss       | -42          |\n","|    explained_variance | -1.19e-07    |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 4699         |\n","|    policy_loss        | -190         |\n","|    reward             | -0.015107999 |\n","|    std                | 1.03         |\n","|    value_loss         | 25.1         |\n","----------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 97          |\n","|    iterations         | 4800        |\n","|    time_elapsed       | 246         |\n","|    total_timesteps    | 24000       |\n","| train/                |             |\n","|    entropy_loss       | -42         |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 4799        |\n","|    policy_loss        | -172        |\n","|    reward             | -0.72587234 |\n","|    std                | 1.03        |\n","|    value_loss         | 24          |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 4900       |\n","|    time_elapsed       | 251        |\n","|    total_timesteps    | 24500      |\n","| train/                |            |\n","|    entropy_loss       | -42.1      |\n","|    explained_variance | 1.79e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4899       |\n","|    policy_loss        | -57.2      |\n","|    reward             | -0.3070341 |\n","|    std                | 1.03       |\n","|    value_loss         | 3.31       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 5000       |\n","|    time_elapsed       | 256        |\n","|    total_timesteps    | 25000      |\n","| train/                |            |\n","|    entropy_loss       | -42.1      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 4999       |\n","|    policy_loss        | -66.1      |\n","|    reward             | -2.3788307 |\n","|    std                | 1.04       |\n","|    value_loss         | 5.61       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 5100       |\n","|    time_elapsed       | 261        |\n","|    total_timesteps    | 25500      |\n","| train/                |            |\n","|    entropy_loss       | -42.1      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5099       |\n","|    policy_loss        | 117        |\n","|    reward             | -0.6340669 |\n","|    std                | 1.04       |\n","|    value_loss         | 29.4       |\n","--------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 97       |\n","|    iterations         | 5200     |\n","|    time_elapsed       | 266      |\n","|    total_timesteps    | 26000    |\n","| train/                |          |\n","|    entropy_loss       | -42.2    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 5199     |\n","|    policy_loss        | -573     |\n","|    reward             | 5.664178 |\n","|    std                | 1.04     |\n","|    value_loss         | 217      |\n","------------------------------------\n","day: 2892, episode: 10\n","begin_total_asset: 1000000.00\n","end_total_asset: 5254994.28\n","total_reward: 4254994.28\n","total_cost: 18326.93\n","total_trades: 47807\n","Sharpe: 0.942\n","=================================\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 5300       |\n","|    time_elapsed       | 271        |\n","|    total_timesteps    | 26500      |\n","| train/                |            |\n","|    entropy_loss       | -42.3      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5299       |\n","|    policy_loss        | -30.6      |\n","|    reward             | 0.46800944 |\n","|    std                | 1.04       |\n","|    value_loss         | 0.634      |\n","--------------------------------------\n","----------------------------------------\n","| time/                 |              |\n","|    fps                | 97           |\n","|    iterations         | 5400         |\n","|    time_elapsed       | 276          |\n","|    total_timesteps    | 27000        |\n","| train/                |              |\n","|    entropy_loss       | -42.2        |\n","|    explained_variance | 0            |\n","|    learning_rate      | 0.0007       |\n","|    n_updates          | 5399         |\n","|    policy_loss        | -29.5        |\n","|    reward             | -0.025204943 |\n","|    std                | 1.04         |\n","|    value_loss         | 4.78         |\n","----------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 5500      |\n","|    time_elapsed       | 282       |\n","|    total_timesteps    | 27500     |\n","| train/                |           |\n","|    entropy_loss       | -42.3     |\n","|    explained_variance | 0.0043    |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5499      |\n","|    policy_loss        | 131       |\n","|    reward             | 3.3195634 |\n","|    std                | 1.04      |\n","|    value_loss         | 20.9      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 5600       |\n","|    time_elapsed       | 287        |\n","|    total_timesteps    | 28000      |\n","| train/                |            |\n","|    entropy_loss       | -42.3      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5599       |\n","|    policy_loss        | -226       |\n","|    reward             | -2.6896014 |\n","|    std                | 1.04       |\n","|    value_loss         | 66.7       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 5700       |\n","|    time_elapsed       | 292        |\n","|    total_timesteps    | 28500      |\n","| train/                |            |\n","|    entropy_loss       | -42.3      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5699       |\n","|    policy_loss        | -89.5      |\n","|    reward             | -0.4964343 |\n","|    std                | 1.04       |\n","|    value_loss         | 13.8       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 5800      |\n","|    time_elapsed       | 297       |\n","|    total_timesteps    | 29000     |\n","| train/                |           |\n","|    entropy_loss       | -42.3     |\n","|    explained_variance | 0.00749   |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 5799      |\n","|    policy_loss        | -0.31     |\n","|    reward             | 2.8640895 |\n","|    std                | 1.04      |\n","|    value_loss         | 3.75      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 5900       |\n","|    time_elapsed       | 302        |\n","|    total_timesteps    | 29500      |\n","| train/                |            |\n","|    entropy_loss       | -42.3      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5899       |\n","|    policy_loss        | 18.8       |\n","|    reward             | -0.3245916 |\n","|    std                | 1.04       |\n","|    value_loss         | 1.07       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 6000       |\n","|    time_elapsed       | 307        |\n","|    total_timesteps    | 30000      |\n","| train/                |            |\n","|    entropy_loss       | -42.4      |\n","|    explained_variance | 5.96e-08   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 5999       |\n","|    policy_loss        | 247        |\n","|    reward             | -3.3856962 |\n","|    std                | 1.05       |\n","|    value_loss         | 34.5       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 6100      |\n","|    time_elapsed       | 312       |\n","|    total_timesteps    | 30500     |\n","| train/                |           |\n","|    entropy_loss       | -42.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6099      |\n","|    policy_loss        | -59       |\n","|    reward             | -5.634521 |\n","|    std                | 1.05      |\n","|    value_loss         | 14.1      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 6200      |\n","|    time_elapsed       | 317       |\n","|    total_timesteps    | 31000     |\n","| train/                |           |\n","|    entropy_loss       | -42.4     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6199      |\n","|    policy_loss        | -200      |\n","|    reward             | -1.859122 |\n","|    std                | 1.05      |\n","|    value_loss         | 24.2      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 6300      |\n","|    time_elapsed       | 322       |\n","|    total_timesteps    | 31500     |\n","| train/                |           |\n","|    entropy_loss       | -42.4     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6299      |\n","|    policy_loss        | 207       |\n","|    reward             | 5.9318094 |\n","|    std                | 1.05      |\n","|    value_loss         | 54.6      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 6400      |\n","|    time_elapsed       | 327       |\n","|    total_timesteps    | 32000     |\n","| train/                |           |\n","|    entropy_loss       | -42.4     |\n","|    explained_variance | -0.00152  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6399      |\n","|    policy_loss        | 169       |\n","|    reward             | 2.8314283 |\n","|    std                | 1.05      |\n","|    value_loss         | 20.2      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 6500      |\n","|    time_elapsed       | 332       |\n","|    total_timesteps    | 32500     |\n","| train/                |           |\n","|    entropy_loss       | -42.4     |\n","|    explained_variance | -0.00127  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6499      |\n","|    policy_loss        | -9.52     |\n","|    reward             | -4.260629 |\n","|    std                | 1.05      |\n","|    value_loss         | 7.44      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 6600       |\n","|    time_elapsed       | 337        |\n","|    total_timesteps    | 33000      |\n","| train/                |            |\n","|    entropy_loss       | -42.3      |\n","|    explained_variance | -0.00174   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6599       |\n","|    policy_loss        | -98.2      |\n","|    reward             | 0.56521726 |\n","|    std                | 1.04       |\n","|    value_loss         | 10.8       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 6700      |\n","|    time_elapsed       | 342       |\n","|    total_timesteps    | 33500     |\n","| train/                |           |\n","|    entropy_loss       | -42.3     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 6699      |\n","|    policy_loss        | -756      |\n","|    reward             | -8.121113 |\n","|    std                | 1.04      |\n","|    value_loss         | 446       |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 6800       |\n","|    time_elapsed       | 347        |\n","|    total_timesteps    | 34000      |\n","| train/                |            |\n","|    entropy_loss       | -42.4      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6799       |\n","|    policy_loss        | -276       |\n","|    reward             | 0.25341696 |\n","|    std                | 1.05       |\n","|    value_loss         | 48.4       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 6900       |\n","|    time_elapsed       | 352        |\n","|    total_timesteps    | 34500      |\n","| train/                |            |\n","|    entropy_loss       | -42.4      |\n","|    explained_variance | 5.96e-08   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6899       |\n","|    policy_loss        | -357       |\n","|    reward             | -0.7921618 |\n","|    std                | 1.05       |\n","|    value_loss         | 96         |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 7000       |\n","|    time_elapsed       | 357        |\n","|    total_timesteps    | 35000      |\n","| train/                |            |\n","|    entropy_loss       | -42.4      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 6999       |\n","|    policy_loss        | 55.9       |\n","|    reward             | 0.12123182 |\n","|    std                | 1.05       |\n","|    value_loss         | 2.26       |\n","--------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 97       |\n","|    iterations         | 7100     |\n","|    time_elapsed       | 363      |\n","|    total_timesteps    | 35500    |\n","| train/                |          |\n","|    entropy_loss       | -42.4    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 7099     |\n","|    policy_loss        | 72.6     |\n","|    reward             | 2.139642 |\n","|    std                | 1.05     |\n","|    value_loss         | 4.59     |\n","------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 7200      |\n","|    time_elapsed       | 368       |\n","|    total_timesteps    | 36000     |\n","| train/                |           |\n","|    entropy_loss       | -42.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7199      |\n","|    policy_loss        | -341      |\n","|    reward             | 1.2508403 |\n","|    std                | 1.05      |\n","|    value_loss         | 69.7      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 7300      |\n","|    time_elapsed       | 373       |\n","|    total_timesteps    | 36500     |\n","| train/                |           |\n","|    entropy_loss       | -42.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7299      |\n","|    policy_loss        | -117      |\n","|    reward             | 1.1849684 |\n","|    std                | 1.05      |\n","|    value_loss         | 17.2      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 7400       |\n","|    time_elapsed       | 378        |\n","|    total_timesteps    | 37000      |\n","| train/                |            |\n","|    entropy_loss       | -42.5      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7399       |\n","|    policy_loss        | 129        |\n","|    reward             | -10.238014 |\n","|    std                | 1.05       |\n","|    value_loss         | 19.4       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 7500       |\n","|    time_elapsed       | 383        |\n","|    total_timesteps    | 37500      |\n","| train/                |            |\n","|    entropy_loss       | -42.5      |\n","|    explained_variance | -1.19e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7499       |\n","|    policy_loss        | 331        |\n","|    reward             | -16.486437 |\n","|    std                | 1.05       |\n","|    value_loss         | 74.7       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 7600       |\n","|    time_elapsed       | 388        |\n","|    total_timesteps    | 38000      |\n","| train/                |            |\n","|    entropy_loss       | -42.6      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7599       |\n","|    policy_loss        | -116       |\n","|    reward             | 0.56380445 |\n","|    std                | 1.05       |\n","|    value_loss         | 7.57       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 7700      |\n","|    time_elapsed       | 393       |\n","|    total_timesteps    | 38500     |\n","| train/                |           |\n","|    entropy_loss       | -42.6     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7699      |\n","|    policy_loss        | -155      |\n","|    reward             | 1.5040071 |\n","|    std                | 1.05      |\n","|    value_loss         | 14.2      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 7800       |\n","|    time_elapsed       | 398        |\n","|    total_timesteps    | 39000      |\n","| train/                |            |\n","|    entropy_loss       | -42.6      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7799       |\n","|    policy_loss        | -33.2      |\n","|    reward             | -1.8359262 |\n","|    std                | 1.05       |\n","|    value_loss         | 4.52       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 7900      |\n","|    time_elapsed       | 403       |\n","|    total_timesteps    | 39500     |\n","| train/                |           |\n","|    entropy_loss       | -42.5     |\n","|    explained_variance | 1.19e-07  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 7899      |\n","|    policy_loss        | 342       |\n","|    reward             | 6.5341473 |\n","|    std                | 1.05      |\n","|    value_loss         | 104       |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 8000       |\n","|    time_elapsed       | 408        |\n","|    total_timesteps    | 40000      |\n","| train/                |            |\n","|    entropy_loss       | -42.5      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 7999       |\n","|    policy_loss        | -388       |\n","|    reward             | -3.0794103 |\n","|    std                | 1.05       |\n","|    value_loss         | 81.5       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 8100      |\n","|    time_elapsed       | 413       |\n","|    total_timesteps    | 40500     |\n","| train/                |           |\n","|    entropy_loss       | -42.5     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8099      |\n","|    policy_loss        | 352       |\n","|    reward             | 14.259704 |\n","|    std                | 1.05      |\n","|    value_loss         | 119       |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 97          |\n","|    iterations         | 8200        |\n","|    time_elapsed       | 418         |\n","|    total_timesteps    | 41000       |\n","| train/                |             |\n","|    entropy_loss       | -42.6       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 8199        |\n","|    policy_loss        | -21.1       |\n","|    reward             | -0.10387242 |\n","|    std                | 1.05        |\n","|    value_loss         | 0.564       |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 8300       |\n","|    time_elapsed       | 423        |\n","|    total_timesteps    | 41500      |\n","| train/                |            |\n","|    entropy_loss       | -42.6      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8299       |\n","|    policy_loss        | 58.6       |\n","|    reward             | -1.6619813 |\n","|    std                | 1.06       |\n","|    value_loss         | 2.56       |\n","--------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 8400       |\n","|    time_elapsed       | 428        |\n","|    total_timesteps    | 42000      |\n","| train/                |            |\n","|    entropy_loss       | -42.7      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8399       |\n","|    policy_loss        | -3.45      |\n","|    reward             | -2.9833686 |\n","|    std                | 1.06       |\n","|    value_loss         | 0.983      |\n","--------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 97          |\n","|    iterations         | 8500        |\n","|    time_elapsed       | 433         |\n","|    total_timesteps    | 42500       |\n","| train/                |             |\n","|    entropy_loss       | -42.7       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 8499        |\n","|    policy_loss        | -110        |\n","|    reward             | -0.15088959 |\n","|    std                | 1.06        |\n","|    value_loss         | 7.27        |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 8600      |\n","|    time_elapsed       | 439       |\n","|    total_timesteps    | 43000     |\n","| train/                |           |\n","|    entropy_loss       | -42.8     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8599      |\n","|    policy_loss        | 120       |\n","|    reward             | -13.49293 |\n","|    std                | 1.06      |\n","|    value_loss         | 57.8      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 8700       |\n","|    time_elapsed       | 444        |\n","|    total_timesteps    | 43500      |\n","| train/                |            |\n","|    entropy_loss       | -42.8      |\n","|    explained_variance | 1.19e-07   |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8699       |\n","|    policy_loss        | -6.08      |\n","|    reward             | 0.33665782 |\n","|    std                | 1.06       |\n","|    value_loss         | 1.64       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 8800      |\n","|    time_elapsed       | 449       |\n","|    total_timesteps    | 44000     |\n","| train/                |           |\n","|    entropy_loss       | -42.8     |\n","|    explained_variance | 5.96e-08  |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 8799      |\n","|    policy_loss        | -63.8     |\n","|    reward             | 1.0940788 |\n","|    std                | 1.06      |\n","|    value_loss         | 2.58      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 97          |\n","|    iterations         | 8900        |\n","|    time_elapsed       | 454         |\n","|    total_timesteps    | 44500       |\n","| train/                |             |\n","|    entropy_loss       | -42.9       |\n","|    explained_variance | 0           |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 8899        |\n","|    policy_loss        | 113         |\n","|    reward             | -0.09023738 |\n","|    std                | 1.06        |\n","|    value_loss         | 7.57        |\n","---------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 97         |\n","|    iterations         | 9000       |\n","|    time_elapsed       | 459        |\n","|    total_timesteps    | 45000      |\n","| train/                |            |\n","|    entropy_loss       | -42.8      |\n","|    explained_variance | 0          |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 8999       |\n","|    policy_loss        | 89.7       |\n","|    reward             | 0.10650838 |\n","|    std                | 1.06       |\n","|    value_loss         | 7.75       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 9100      |\n","|    time_elapsed       | 464       |\n","|    total_timesteps    | 45500     |\n","| train/                |           |\n","|    entropy_loss       | -42.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 9099      |\n","|    policy_loss        | 4.73      |\n","|    reward             | 3.2266102 |\n","|    std                | 1.06      |\n","|    value_loss         | 0.447     |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 97        |\n","|    iterations         | 9200      |\n","|    time_elapsed       | 469       |\n","|    total_timesteps    | 46000     |\n","| train/                |           |\n","|    entropy_loss       | -42.9     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 9199      |\n","|    policy_loss        | 57.3      |\n","|    reward             | 1.6439487 |\n","|    std                | 1.06      |\n","|    value_loss         | 4.37      |\n","-------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 9300      |\n","|    time_elapsed       | 474       |\n","|    total_timesteps    | 46500     |\n","| train/                |           |\n","|    entropy_loss       | -42.9     |\n","|    explained_variance | -1.19e-07 |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 9299      |\n","|    policy_loss        | -146      |\n","|    reward             | 1.1052117 |\n","|    std                | 1.07      |\n","|    value_loss         | 14.1      |\n","-------------------------------------\n","--------------------------------------\n","| time/                 |            |\n","|    fps                | 98         |\n","|    iterations         | 9400       |\n","|    time_elapsed       | 479        |\n","|    total_timesteps    | 47000      |\n","| train/                |            |\n","|    entropy_loss       | -42.9      |\n","|    explained_variance | -2.38e-07  |\n","|    learning_rate      | 0.0007     |\n","|    n_updates          | 9399       |\n","|    policy_loss        | 98.5       |\n","|    reward             | 0.13853374 |\n","|    std                | 1.07       |\n","|    value_loss         | 9.05       |\n","--------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 9500      |\n","|    time_elapsed       | 484       |\n","|    total_timesteps    | 47500     |\n","| train/                |           |\n","|    entropy_loss       | -43       |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 9499      |\n","|    policy_loss        | -28.4     |\n","|    reward             | 0.8650588 |\n","|    std                | 1.07      |\n","|    value_loss         | 1.57      |\n","-------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 98          |\n","|    iterations         | 9600        |\n","|    time_elapsed       | 489         |\n","|    total_timesteps    | 48000       |\n","| train/                |             |\n","|    entropy_loss       | -43.1       |\n","|    explained_variance | 0.0956      |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 9599        |\n","|    policy_loss        | -112        |\n","|    reward             | -0.30570126 |\n","|    std                | 1.07        |\n","|    value_loss         | 8.1         |\n","---------------------------------------\n","-------------------------------------\n","| time/                 |           |\n","|    fps                | 98        |\n","|    iterations         | 9700      |\n","|    time_elapsed       | 494       |\n","|    total_timesteps    | 48500     |\n","| train/                |           |\n","|    entropy_loss       | -43.2     |\n","|    explained_variance | 0         |\n","|    learning_rate      | 0.0007    |\n","|    n_updates          | 9699      |\n","|    policy_loss        | 45.1      |\n","|    reward             | 2.1892767 |\n","|    std                | 1.07      |\n","|    value_loss         | 2.12      |\n","-------------------------------------\n","------------------------------------\n","| time/                 |          |\n","|    fps                | 98       |\n","|    iterations         | 9800     |\n","|    time_elapsed       | 499      |\n","|    total_timesteps    | 49000    |\n","| train/                |          |\n","|    entropy_loss       | -43.1    |\n","|    explained_variance | 0        |\n","|    learning_rate      | 0.0007   |\n","|    n_updates          | 9799     |\n","|    policy_loss        | 104      |\n","|    reward             | 8.743324 |\n","|    std                | 1.07     |\n","|    value_loss         | 49.2     |\n","------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 98          |\n","|    iterations         | 9900        |\n","|    time_elapsed       | 504         |\n","|    total_timesteps    | 49500       |\n","| train/                |             |\n","|    entropy_loss       | -43.2       |\n","|    explained_variance | -0.000561   |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 9899        |\n","|    policy_loss        | 34.1        |\n","|    reward             | -0.17457703 |\n","|    std                | 1.08        |\n","|    value_loss         | 0.794       |\n","---------------------------------------\n","---------------------------------------\n","| time/                 |             |\n","|    fps                | 98          |\n","|    iterations         | 10000       |\n","|    time_elapsed       | 509         |\n","|    total_timesteps    | 50000       |\n","| train/                |             |\n","|    entropy_loss       | -43.3       |\n","|    explained_variance | 5.96e-08    |\n","|    learning_rate      | 0.0007      |\n","|    n_updates          | 9999        |\n","|    policy_loss        | 79.6        |\n","|    reward             | 0.052444983 |\n","|    std                | 1.08        |\n","|    value_loss         | 4.53        |\n","---------------------------------------\n"]}],"source":["trained_a2c = agent.train_model(model=model_a2c,\n","                             tb_log_name='a2c',\n","                             total_timesteps=50000) if if_using_a2c else None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjCWfgsg3sVa"},"outputs":[],"source":["trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"]},{"cell_type":"markdown","metadata":{"id":"MRiOtrywfAo1"},"source":["### Agent 2: DDPG"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8442,"status":"ok","timestamp":1691998630256,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"M2YadjfnLwgt","outputId":"c91b79fd-4f57-4df3-b0fc-024b7ad54e43"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n","Using cpu device\n","Logging to results/ddpg\n"]}],"source":["agent = DRLAgent(env = env_train)\n","model_ddpg = agent.get_model(\"ddpg\")\n","\n","if if_using_ddpg:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + '/ddpg'\n","  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_ddpg.set_logger(new_logger_ddpg)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":668},"executionInfo":{"elapsed":49752,"status":"error","timestamp":1691998833366,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"tCDa78rqfO_a","outputId":"bd1c384e-eba9-4f5e-fb87-df36325792d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------------------------\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 60       |\n","|    time_elapsed    | 190      |\n","|    total_timesteps | 11572    |\n","| train/             |          |\n","|    actor_loss      | -52.2    |\n","|    critic_loss     | 1.18e+04 |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 8679     |\n","|    reward          | 6.205496 |\n","---------------------------------\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 50       |\n","|    time_elapsed    | 461      |\n","|    total_timesteps | 23144    |\n","| train/             |          |\n","|    actor_loss      | 32.8     |\n","|    critic_loss     | 67.3     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 20251    |\n","|    reward          | 6.205496 |\n","---------------------------------\n","day: 2892, episode: 10\n","begin_total_asset: 1000000.00\n","end_total_asset: 5300085.61\n","total_reward: 4300085.61\n","total_cost: 1495.74\n","total_trades: 46352\n","Sharpe: 0.935\n","=================================\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 46       |\n","|    time_elapsed    | 742      |\n","|    total_timesteps | 34716    |\n","| train/             |          |\n","|    actor_loss      | 13.4     |\n","|    critic_loss     | 10.5     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 31823    |\n","|    reward          | 6.205496 |\n","---------------------------------\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 43       |\n","|    time_elapsed    | 1057     |\n","|    total_timesteps | 46288    |\n","| train/             |          |\n","|    actor_loss      | 0.56     |\n","|    critic_loss     | 6.32     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 43395    |\n","|    reward          | 6.205496 |\n","---------------------------------\n"]}],"source":["trained_ddpg = agent.train_model(model=model_ddpg,\n","                             tb_log_name='ddpg',\n","                             total_timesteps=50000) if if_using_ddpg else None"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1691998833367,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"ne6M2R-WvrUQ"},"outputs":[],"source":["trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None"]},{"cell_type":"markdown","metadata":{"id":"_gDkU-j-fCmZ"},"source":["### Agent 3: PPO"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1691998833367,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"y5D5PFUhMzSV"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n","Using cpu device\n","Logging to results/ppo\n"]}],"source":["agent = DRLAgent(env = env_train)\n","PPO_PARAMS = {\n","    \"n_steps\": 2048,\n","    \"ent_coef\": 0.01,\n","    \"learning_rate\": 0.00025,\n","    \"batch_size\": 128,\n","}\n","model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n","\n","if if_using_ppo:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + '/ppo'\n","  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_ppo.set_logger(new_logger_ppo)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1691998833367,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"Gt8eIQKYM4G3"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------\n","| time/              |           |\n","|    fps             | 93        |\n","|    iterations      | 1         |\n","|    time_elapsed    | 21        |\n","|    total_timesteps | 2048      |\n","| train/             |           |\n","|    reward          | 0.2830317 |\n","----------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 89          |\n","|    iterations           | 2           |\n","|    time_elapsed         | 45          |\n","|    total_timesteps      | 4096        |\n","| train/                  |             |\n","|    approx_kl            | 0.017405685 |\n","|    clip_fraction        | 0.198       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.2       |\n","|    explained_variance   | 0.00116     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 4.47        |\n","|    n_updates            | 10          |\n","|    policy_gradient_loss | -0.0175     |\n","|    reward               | 0.84129477  |\n","|    std                  | 1           |\n","|    value_loss           | 13.6        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 90          |\n","|    iterations           | 3           |\n","|    time_elapsed         | 67          |\n","|    total_timesteps      | 6144        |\n","| train/                  |             |\n","|    approx_kl            | 0.016096935 |\n","|    clip_fraction        | 0.189       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.3       |\n","|    explained_variance   | 0.00366     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 26.5        |\n","|    n_updates            | 20          |\n","|    policy_gradient_loss | -0.0168     |\n","|    reward               | -1.2504709  |\n","|    std                  | 1.01        |\n","|    value_loss           | 50.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 90          |\n","|    iterations           | 4           |\n","|    time_elapsed         | 90          |\n","|    total_timesteps      | 8192        |\n","| train/                  |             |\n","|    approx_kl            | 0.016075732 |\n","|    clip_fraction        | 0.166       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.3       |\n","|    explained_variance   | -0.00234    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 30.9        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0208     |\n","|    reward               | 2.7863283   |\n","|    std                  | 1.01        |\n","|    value_loss           | 65.3        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 91          |\n","|    iterations           | 5           |\n","|    time_elapsed         | 111         |\n","|    total_timesteps      | 10240       |\n","| train/                  |             |\n","|    approx_kl            | 0.015105108 |\n","|    clip_fraction        | 0.18        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | 0.0106      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 12.2        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.0187     |\n","|    reward               | 4.255176    |\n","|    std                  | 1.01        |\n","|    value_loss           | 21.4        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 92          |\n","|    iterations           | 6           |\n","|    time_elapsed         | 132         |\n","|    total_timesteps      | 12288       |\n","| train/                  |             |\n","|    approx_kl            | 0.018215554 |\n","|    clip_fraction        | 0.194       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.4       |\n","|    explained_variance   | -0.00216    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 51.9        |\n","|    n_updates            | 50          |\n","|    policy_gradient_loss | -0.0188     |\n","|    reward               | 2.2338884   |\n","|    std                  | 1.01        |\n","|    value_loss           | 73.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 90          |\n","|    iterations           | 7           |\n","|    time_elapsed         | 159         |\n","|    total_timesteps      | 14336       |\n","| train/                  |             |\n","|    approx_kl            | 0.020637745 |\n","|    clip_fraction        | 0.173       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.5       |\n","|    explained_variance   | -0.00627    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 42.6        |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.0121     |\n","|    reward               | 1.5451865   |\n","|    std                  | 1.01        |\n","|    value_loss           | 73.5        |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 87         |\n","|    iterations           | 8          |\n","|    time_elapsed         | 186        |\n","|    total_timesteps      | 16384      |\n","| train/                  |            |\n","|    approx_kl            | 0.02661927 |\n","|    clip_fraction        | 0.252      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.5      |\n","|    explained_variance   | -0.0375    |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 20.4       |\n","|    n_updates            | 70         |\n","|    policy_gradient_loss | -0.0155    |\n","|    reward               | 0.31631738 |\n","|    std                  | 1.01       |\n","|    value_loss           | 45.5       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 86          |\n","|    iterations           | 9           |\n","|    time_elapsed         | 212         |\n","|    total_timesteps      | 18432       |\n","| train/                  |             |\n","|    approx_kl            | 0.019999199 |\n","|    clip_fraction        | 0.202       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.6       |\n","|    explained_variance   | -0.00301    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 19.7        |\n","|    n_updates            | 80          |\n","|    policy_gradient_loss | -0.0187     |\n","|    reward               | 0.060662318 |\n","|    std                  | 1.02        |\n","|    value_loss           | 50.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 87          |\n","|    iterations           | 10          |\n","|    time_elapsed         | 234         |\n","|    total_timesteps      | 20480       |\n","| train/                  |             |\n","|    approx_kl            | 0.017514288 |\n","|    clip_fraction        | 0.224       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.6       |\n","|    explained_variance   | 0.00276     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 38.3        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.02       |\n","|    reward               | 0.75291777  |\n","|    std                  | 1.02        |\n","|    value_loss           | 103         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 85          |\n","|    iterations           | 11          |\n","|    time_elapsed         | 264         |\n","|    total_timesteps      | 22528       |\n","| train/                  |             |\n","|    approx_kl            | 0.024214743 |\n","|    clip_fraction        | 0.262       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.7       |\n","|    explained_variance   | 0.0167      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 41.4        |\n","|    n_updates            | 100         |\n","|    policy_gradient_loss | -0.0157     |\n","|    reward               | 2.3535054   |\n","|    std                  | 1.02        |\n","|    value_loss           | 99.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 85          |\n","|    iterations           | 12          |\n","|    time_elapsed         | 287         |\n","|    total_timesteps      | 24576       |\n","| train/                  |             |\n","|    approx_kl            | 0.021565035 |\n","|    clip_fraction        | 0.224       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.7       |\n","|    explained_variance   | 0.0225      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 11.9        |\n","|    n_updates            | 110         |\n","|    policy_gradient_loss | -0.0124     |\n","|    reward               | -0.33481997 |\n","|    std                  | 1.02        |\n","|    value_loss           | 27.9        |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 83         |\n","|    iterations           | 13         |\n","|    time_elapsed         | 317        |\n","|    total_timesteps      | 26624      |\n","| train/                  |            |\n","|    approx_kl            | 0.02029084 |\n","|    clip_fraction        | 0.191      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -41.8      |\n","|    explained_variance   | 0.00259    |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 54.2       |\n","|    n_updates            | 120        |\n","|    policy_gradient_loss | -0.0191    |\n","|    reward               | 0.5272727  |\n","|    std                  | 1.02       |\n","|    value_loss           | 113        |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 83          |\n","|    iterations           | 14          |\n","|    time_elapsed         | 345         |\n","|    total_timesteps      | 28672       |\n","| train/                  |             |\n","|    approx_kl            | 0.017776184 |\n","|    clip_fraction        | 0.213       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.8       |\n","|    explained_variance   | 0.00621     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 37.9        |\n","|    n_updates            | 130         |\n","|    policy_gradient_loss | -0.0177     |\n","|    reward               | -1.1773337  |\n","|    std                  | 1.02        |\n","|    value_loss           | 154         |\n","-----------------------------------------\n","day: 2892, episode: 30\n","begin_total_asset: 1000000.00\n","end_total_asset: 5045580.45\n","total_reward: 4045580.45\n","total_cost: 317272.41\n","total_trades: 79242\n","Sharpe: 0.876\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 15          |\n","|    time_elapsed         | 378         |\n","|    total_timesteps      | 30720       |\n","| train/                  |             |\n","|    approx_kl            | 0.021812594 |\n","|    clip_fraction        | 0.259       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -41.9       |\n","|    explained_variance   | 0.00629     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 21.1        |\n","|    n_updates            | 140         |\n","|    policy_gradient_loss | -0.0164     |\n","|    reward               | 6.3363457   |\n","|    std                  | 1.03        |\n","|    value_loss           | 42.6        |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 80           |\n","|    iterations           | 16           |\n","|    time_elapsed         | 408          |\n","|    total_timesteps      | 32768        |\n","| train/                  |              |\n","|    approx_kl            | 0.0154499505 |\n","|    clip_fraction        | 0.118        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -42          |\n","|    explained_variance   | 0.00468      |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 30.8         |\n","|    n_updates            | 150          |\n","|    policy_gradient_loss | -0.0141      |\n","|    reward               | 0.223075     |\n","|    std                  | 1.03         |\n","|    value_loss           | 86.6         |\n","------------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 80         |\n","|    iterations           | 17         |\n","|    time_elapsed         | 432        |\n","|    total_timesteps      | 34816      |\n","| train/                  |            |\n","|    approx_kl            | 0.02492752 |\n","|    clip_fraction        | 0.235      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -42        |\n","|    explained_variance   | 0.00881    |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 85.8       |\n","|    n_updates            | 160        |\n","|    policy_gradient_loss | -0.0144    |\n","|    reward               | 0.50624114 |\n","|    std                  | 1.03       |\n","|    value_loss           | 154        |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 80          |\n","|    iterations           | 18          |\n","|    time_elapsed         | 455         |\n","|    total_timesteps      | 36864       |\n","| train/                  |             |\n","|    approx_kl            | 0.029583074 |\n","|    clip_fraction        | 0.212       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.1       |\n","|    explained_variance   | 0.00334     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 55.7        |\n","|    n_updates            | 170         |\n","|    policy_gradient_loss | -0.0119     |\n","|    reward               | -0.1952441  |\n","|    std                  | 1.03        |\n","|    value_loss           | 92.3        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 19          |\n","|    time_elapsed         | 480         |\n","|    total_timesteps      | 38912       |\n","| train/                  |             |\n","|    approx_kl            | 0.02019985  |\n","|    clip_fraction        | 0.25        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.1       |\n","|    explained_variance   | 0.0373      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 12.6        |\n","|    n_updates            | 180         |\n","|    policy_gradient_loss | -0.0179     |\n","|    reward               | -0.50728637 |\n","|    std                  | 1.03        |\n","|    value_loss           | 23.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 20          |\n","|    time_elapsed         | 503         |\n","|    total_timesteps      | 40960       |\n","| train/                  |             |\n","|    approx_kl            | 0.025691211 |\n","|    clip_fraction        | 0.233       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.1       |\n","|    explained_variance   | 0.00571     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 75.5        |\n","|    n_updates            | 190         |\n","|    policy_gradient_loss | -0.0129     |\n","|    reward               | -0.50266457 |\n","|    std                  | 1.04        |\n","|    value_loss           | 93          |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 81         |\n","|    iterations           | 21         |\n","|    time_elapsed         | 525        |\n","|    total_timesteps      | 43008      |\n","| train/                  |            |\n","|    approx_kl            | 0.02694245 |\n","|    clip_fraction        | 0.259      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -42.2      |\n","|    explained_variance   | -2.56e-05  |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 55.6       |\n","|    n_updates            | 200        |\n","|    policy_gradient_loss | -0.0117    |\n","|    reward               | -6.1521597 |\n","|    std                  | 1.04       |\n","|    value_loss           | 74.4       |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 81         |\n","|    iterations           | 22         |\n","|    time_elapsed         | 550        |\n","|    total_timesteps      | 45056      |\n","| train/                  |            |\n","|    approx_kl            | 0.01872759 |\n","|    clip_fraction        | 0.18       |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -42.2      |\n","|    explained_variance   | 0.0109     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 60.6       |\n","|    n_updates            | 210        |\n","|    policy_gradient_loss | -0.0104    |\n","|    reward               | 4.7151337  |\n","|    std                  | 1.04       |\n","|    value_loss           | 128        |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 23          |\n","|    time_elapsed         | 576         |\n","|    total_timesteps      | 47104       |\n","| train/                  |             |\n","|    approx_kl            | 0.016398352 |\n","|    clip_fraction        | 0.125       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.2       |\n","|    explained_variance   | 0.00153     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 382         |\n","|    n_updates            | 220         |\n","|    policy_gradient_loss | -0.0134     |\n","|    reward               | -0.52361083 |\n","|    std                  | 1.04        |\n","|    value_loss           | 550         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 24          |\n","|    time_elapsed         | 600         |\n","|    total_timesteps      | 49152       |\n","| train/                  |             |\n","|    approx_kl            | 0.011438174 |\n","|    clip_fraction        | 0.0847      |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.3       |\n","|    explained_variance   | -0.00141    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 84.9        |\n","|    n_updates            | 230         |\n","|    policy_gradient_loss | -0.0116     |\n","|    reward               | 5.2432337   |\n","|    std                  | 1.04        |\n","|    value_loss           | 353         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 82          |\n","|    iterations           | 25          |\n","|    time_elapsed         | 623         |\n","|    total_timesteps      | 51200       |\n","| train/                  |             |\n","|    approx_kl            | 0.029491544 |\n","|    clip_fraction        | 0.227       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.3       |\n","|    explained_variance   | 0.00596     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 51.6        |\n","|    n_updates            | 240         |\n","|    policy_gradient_loss | -0.00751    |\n","|    reward               | -0.21863018 |\n","|    std                  | 1.04        |\n","|    value_loss           | 146         |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 82         |\n","|    iterations           | 26         |\n","|    time_elapsed         | 647        |\n","|    total_timesteps      | 53248      |\n","| train/                  |            |\n","|    approx_kl            | 0.02922036 |\n","|    clip_fraction        | 0.277      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -42.4      |\n","|    explained_variance   | -0.0236    |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 11.6       |\n","|    n_updates            | 250        |\n","|    policy_gradient_loss | -0.00744   |\n","|    reward               | 0.39824042 |\n","|    std                  | 1.04       |\n","|    value_loss           | 20.4       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 82          |\n","|    iterations           | 27          |\n","|    time_elapsed         | 671         |\n","|    total_timesteps      | 55296       |\n","| train/                  |             |\n","|    approx_kl            | 0.028819397 |\n","|    clip_fraction        | 0.226       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.4       |\n","|    explained_variance   | 0.0222      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 34.2        |\n","|    n_updates            | 260         |\n","|    policy_gradient_loss | -0.0145     |\n","|    reward               | -1.269019   |\n","|    std                  | 1.04        |\n","|    value_loss           | 74.4        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 82          |\n","|    iterations           | 28          |\n","|    time_elapsed         | 699         |\n","|    total_timesteps      | 57344       |\n","| train/                  |             |\n","|    approx_kl            | 0.028198168 |\n","|    clip_fraction        | 0.266       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.4       |\n","|    explained_variance   | -0.000892   |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 26.9        |\n","|    n_updates            | 270         |\n","|    policy_gradient_loss | -0.00826    |\n","|    reward               | -2.7957182  |\n","|    std                  | 1.05        |\n","|    value_loss           | 63.4        |\n","-----------------------------------------\n","day: 2892, episode: 40\n","begin_total_asset: 1000000.00\n","end_total_asset: 3713760.76\n","total_reward: 2713760.76\n","total_cost: 305825.64\n","total_trades: 78084\n","Sharpe: 0.765\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 29          |\n","|    time_elapsed         | 726         |\n","|    total_timesteps      | 59392       |\n","| train/                  |             |\n","|    approx_kl            | 0.016521048 |\n","|    clip_fraction        | 0.182       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.5       |\n","|    explained_variance   | 0.0656      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 13.8        |\n","|    n_updates            | 280         |\n","|    policy_gradient_loss | -0.0131     |\n","|    reward               | 0.078944296 |\n","|    std                  | 1.05        |\n","|    value_loss           | 25          |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 30          |\n","|    time_elapsed         | 752         |\n","|    total_timesteps      | 61440       |\n","| train/                  |             |\n","|    approx_kl            | 0.025639467 |\n","|    clip_fraction        | 0.187       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.5       |\n","|    explained_variance   | 0.016       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 12.8        |\n","|    n_updates            | 290         |\n","|    policy_gradient_loss | -0.0193     |\n","|    reward               | 0.8602439   |\n","|    std                  | 1.05        |\n","|    value_loss           | 41.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 31          |\n","|    time_elapsed         | 777         |\n","|    total_timesteps      | 63488       |\n","| train/                  |             |\n","|    approx_kl            | 0.019066898 |\n","|    clip_fraction        | 0.147       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.6       |\n","|    explained_variance   | 0.0326      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 16.2        |\n","|    n_updates            | 300         |\n","|    policy_gradient_loss | -0.0121     |\n","|    reward               | -0.2681802  |\n","|    std                  | 1.05        |\n","|    value_loss           | 52.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 32          |\n","|    time_elapsed         | 808         |\n","|    total_timesteps      | 65536       |\n","| train/                  |             |\n","|    approx_kl            | 0.025920333 |\n","|    clip_fraction        | 0.266       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.6       |\n","|    explained_variance   | -0.0258     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 22          |\n","|    n_updates            | 310         |\n","|    policy_gradient_loss | -0.00813    |\n","|    reward               | -1.1058873  |\n","|    std                  | 1.05        |\n","|    value_loss           | 42.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 33          |\n","|    time_elapsed         | 833         |\n","|    total_timesteps      | 67584       |\n","| train/                  |             |\n","|    approx_kl            | 0.013822763 |\n","|    clip_fraction        | 0.131       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.6       |\n","|    explained_variance   | 0.0147      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 15.7        |\n","|    n_updates            | 320         |\n","|    policy_gradient_loss | -0.0119     |\n","|    reward               | -0.28737935 |\n","|    std                  | 1.05        |\n","|    value_loss           | 42.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 34          |\n","|    time_elapsed         | 857         |\n","|    total_timesteps      | 69632       |\n","| train/                  |             |\n","|    approx_kl            | 0.023097685 |\n","|    clip_fraction        | 0.164       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.6       |\n","|    explained_variance   | 0.0117      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 70          |\n","|    n_updates            | 330         |\n","|    policy_gradient_loss | -0.00583    |\n","|    reward               | 0.83711106  |\n","|    std                  | 1.05        |\n","|    value_loss           | 121         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 35          |\n","|    time_elapsed         | 881         |\n","|    total_timesteps      | 71680       |\n","| train/                  |             |\n","|    approx_kl            | 0.020613795 |\n","|    clip_fraction        | 0.198       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.7       |\n","|    explained_variance   | 0.009       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 48.6        |\n","|    n_updates            | 340         |\n","|    policy_gradient_loss | -0.00761    |\n","|    reward               | -2.9345818  |\n","|    std                  | 1.06        |\n","|    value_loss           | 60.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 36          |\n","|    time_elapsed         | 904         |\n","|    total_timesteps      | 73728       |\n","| train/                  |             |\n","|    approx_kl            | 0.024325779 |\n","|    clip_fraction        | 0.26        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.8       |\n","|    explained_variance   | 0.0675      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 12.4        |\n","|    n_updates            | 350         |\n","|    policy_gradient_loss | -0.0121     |\n","|    reward               | -5.0133595  |\n","|    std                  | 1.06        |\n","|    value_loss           | 23.3        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 37          |\n","|    time_elapsed         | 928         |\n","|    total_timesteps      | 75776       |\n","| train/                  |             |\n","|    approx_kl            | 0.026427753 |\n","|    clip_fraction        | 0.276       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.8       |\n","|    explained_variance   | 0.0554      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 17.3        |\n","|    n_updates            | 360         |\n","|    policy_gradient_loss | -0.0168     |\n","|    reward               | 0.072886065 |\n","|    std                  | 1.06        |\n","|    value_loss           | 43.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 38          |\n","|    time_elapsed         | 952         |\n","|    total_timesteps      | 77824       |\n","| train/                  |             |\n","|    approx_kl            | 0.024073336 |\n","|    clip_fraction        | 0.298       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.9       |\n","|    explained_variance   | 0.00892     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 54.7        |\n","|    n_updates            | 370         |\n","|    policy_gradient_loss | -0.00265    |\n","|    reward               | -9.090176   |\n","|    std                  | 1.06        |\n","|    value_loss           | 102         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 39          |\n","|    time_elapsed         | 976         |\n","|    total_timesteps      | 79872       |\n","| train/                  |             |\n","|    approx_kl            | 0.031309683 |\n","|    clip_fraction        | 0.234       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.9       |\n","|    explained_variance   | 0.0368      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 25.3        |\n","|    n_updates            | 380         |\n","|    policy_gradient_loss | -0.00926    |\n","|    reward               | -2.800903   |\n","|    std                  | 1.06        |\n","|    value_loss           | 46.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 40          |\n","|    time_elapsed         | 999         |\n","|    total_timesteps      | 81920       |\n","| train/                  |             |\n","|    approx_kl            | 0.025964072 |\n","|    clip_fraction        | 0.26        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -42.9       |\n","|    explained_variance   | 0.0774      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 22.7        |\n","|    n_updates            | 390         |\n","|    policy_gradient_loss | -0.0104     |\n","|    reward               | -1.1546434  |\n","|    std                  | 1.07        |\n","|    value_loss           | 60.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 82          |\n","|    iterations           | 41          |\n","|    time_elapsed         | 1022        |\n","|    total_timesteps      | 83968       |\n","| train/                  |             |\n","|    approx_kl            | 0.015519055 |\n","|    clip_fraction        | 0.165       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43         |\n","|    explained_variance   | 0.00593     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 32.3        |\n","|    n_updates            | 400         |\n","|    policy_gradient_loss | -0.00894    |\n","|    reward               | 0.71861607  |\n","|    std                  | 1.07        |\n","|    value_loss           | 62.8        |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 82         |\n","|    iterations           | 42         |\n","|    time_elapsed         | 1045       |\n","|    total_timesteps      | 86016      |\n","| train/                  |            |\n","|    approx_kl            | 0.04299014 |\n","|    clip_fraction        | 0.41       |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -43.1      |\n","|    explained_variance   | 0.00772    |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 31         |\n","|    n_updates            | 410        |\n","|    policy_gradient_loss | 0.00653    |\n","|    reward               | -0.8335219 |\n","|    std                  | 1.07       |\n","|    value_loss           | 70.7       |\n","----------------------------------------\n","day: 2892, episode: 50\n","begin_total_asset: 1000000.00\n","end_total_asset: 4649743.02\n","total_reward: 3649743.02\n","total_cost: 295752.12\n","total_trades: 76877\n","Sharpe: 0.873\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 82          |\n","|    iterations           | 43          |\n","|    time_elapsed         | 1072        |\n","|    total_timesteps      | 88064       |\n","| train/                  |             |\n","|    approx_kl            | 0.031328075 |\n","|    clip_fraction        | 0.297       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.1       |\n","|    explained_variance   | 0.0677      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 11.7        |\n","|    n_updates            | 420         |\n","|    policy_gradient_loss | -0.00291    |\n","|    reward               | -0.4319967  |\n","|    std                  | 1.07        |\n","|    value_loss           | 27.4        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 82          |\n","|    iterations           | 44          |\n","|    time_elapsed         | 1094        |\n","|    total_timesteps      | 90112       |\n","| train/                  |             |\n","|    approx_kl            | 0.028752249 |\n","|    clip_fraction        | 0.317       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.2       |\n","|    explained_variance   | 0.012       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 25.2        |\n","|    n_updates            | 430         |\n","|    policy_gradient_loss | -0.00954    |\n","|    reward               | 0.19854806  |\n","|    std                  | 1.07        |\n","|    value_loss           | 76.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 82          |\n","|    iterations           | 45          |\n","|    time_elapsed         | 1121        |\n","|    total_timesteps      | 92160       |\n","| train/                  |             |\n","|    approx_kl            | 0.021290906 |\n","|    clip_fraction        | 0.295       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.3       |\n","|    explained_variance   | 0.00146     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 18.8        |\n","|    n_updates            | 440         |\n","|    policy_gradient_loss | -0.00678    |\n","|    reward               | -4.3113656  |\n","|    std                  | 1.08        |\n","|    value_loss           | 46.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 46          |\n","|    time_elapsed         | 1152        |\n","|    total_timesteps      | 94208       |\n","| train/                  |             |\n","|    approx_kl            | 0.027348835 |\n","|    clip_fraction        | 0.296       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.3       |\n","|    explained_variance   | 0.0928      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 14.1        |\n","|    n_updates            | 450         |\n","|    policy_gradient_loss | -0.0111     |\n","|    reward               | -9.196999   |\n","|    std                  | 1.08        |\n","|    value_loss           | 37.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 47          |\n","|    time_elapsed         | 1177        |\n","|    total_timesteps      | 96256       |\n","| train/                  |             |\n","|    approx_kl            | 0.020924225 |\n","|    clip_fraction        | 0.204       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.4       |\n","|    explained_variance   | 0.0109      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 38.5        |\n","|    n_updates            | 460         |\n","|    policy_gradient_loss | -0.0144     |\n","|    reward               | 2.697543    |\n","|    std                  | 1.08        |\n","|    value_loss           | 86.4        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 48          |\n","|    time_elapsed         | 1202        |\n","|    total_timesteps      | 98304       |\n","| train/                  |             |\n","|    approx_kl            | 0.028590254 |\n","|    clip_fraction        | 0.256       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.4       |\n","|    explained_variance   | 0.000332    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 54.6        |\n","|    n_updates            | 470         |\n","|    policy_gradient_loss | -0.00685    |\n","|    reward               | 19.505775   |\n","|    std                  | 1.08        |\n","|    value_loss           | 103         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 49          |\n","|    time_elapsed         | 1225        |\n","|    total_timesteps      | 100352      |\n","| train/                  |             |\n","|    approx_kl            | 0.032847792 |\n","|    clip_fraction        | 0.279       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.5       |\n","|    explained_variance   | 0.000932    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 69.2        |\n","|    n_updates            | 480         |\n","|    policy_gradient_loss | 0.00231     |\n","|    reward               | -1.8729416  |\n","|    std                  | 1.09        |\n","|    value_loss           | 118         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 82          |\n","|    iterations           | 50          |\n","|    time_elapsed         | 1247        |\n","|    total_timesteps      | 102400      |\n","| train/                  |             |\n","|    approx_kl            | 0.022371236 |\n","|    clip_fraction        | 0.234       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.5       |\n","|    explained_variance   | 0.104       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 17.9        |\n","|    n_updates            | 490         |\n","|    policy_gradient_loss | -0.0125     |\n","|    reward               | -0.26171005 |\n","|    std                  | 1.09        |\n","|    value_loss           | 35.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 51          |\n","|    time_elapsed         | 1277        |\n","|    total_timesteps      | 104448      |\n","| train/                  |             |\n","|    approx_kl            | 0.020917304 |\n","|    clip_fraction        | 0.195       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.6       |\n","|    explained_variance   | -0.00456    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 29.2        |\n","|    n_updates            | 500         |\n","|    policy_gradient_loss | -0.00705    |\n","|    reward               | -0.4625383  |\n","|    std                  | 1.09        |\n","|    value_loss           | 101         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 81          |\n","|    iterations           | 52          |\n","|    time_elapsed         | 1299        |\n","|    total_timesteps      | 106496      |\n","| train/                  |             |\n","|    approx_kl            | 0.018042348 |\n","|    clip_fraction        | 0.233       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.6       |\n","|    explained_variance   | 0.0157      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 109         |\n","|    n_updates            | 510         |\n","|    policy_gradient_loss | -0.00282    |\n","|    reward               | -1.8427039  |\n","|    std                  | 1.09        |\n","|    value_loss           | 189         |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 82         |\n","|    iterations           | 53         |\n","|    time_elapsed         | 1319       |\n","|    total_timesteps      | 108544     |\n","| train/                  |            |\n","|    approx_kl            | 0.03323725 |\n","|    clip_fraction        | 0.375      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -43.7      |\n","|    explained_variance   | 0.0655     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 20.7       |\n","|    n_updates            | 520        |\n","|    policy_gradient_loss | -0.00561   |\n","|    reward               | -1.1679254 |\n","|    std                  | 1.09       |\n","|    value_loss           | 39.4       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 82          |\n","|    iterations           | 54          |\n","|    time_elapsed         | 1341        |\n","|    total_timesteps      | 110592      |\n","| train/                  |             |\n","|    approx_kl            | 0.024622593 |\n","|    clip_fraction        | 0.252       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.7       |\n","|    explained_variance   | 0.0512      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 63.7        |\n","|    n_updates            | 530         |\n","|    policy_gradient_loss | -0.0135     |\n","|    reward               | 1.2939596   |\n","|    std                  | 1.09        |\n","|    value_loss           | 111         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 82          |\n","|    iterations           | 55          |\n","|    time_elapsed         | 1361        |\n","|    total_timesteps      | 112640      |\n","| train/                  |             |\n","|    approx_kl            | 0.016362365 |\n","|    clip_fraction        | 0.146       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.7       |\n","|    explained_variance   | 0.0346      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 47.8        |\n","|    n_updates            | 540         |\n","|    policy_gradient_loss | -0.00965    |\n","|    reward               | 1.0815027   |\n","|    std                  | 1.09        |\n","|    value_loss           | 117         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 82          |\n","|    iterations           | 56          |\n","|    time_elapsed         | 1382        |\n","|    total_timesteps      | 114688      |\n","| train/                  |             |\n","|    approx_kl            | 0.029075801 |\n","|    clip_fraction        | 0.266       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.8       |\n","|    explained_variance   | 0.0484      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 32.4        |\n","|    n_updates            | 550         |\n","|    policy_gradient_loss | -0.00119    |\n","|    reward               | 1.5861431   |\n","|    std                  | 1.1         |\n","|    value_loss           | 64.6        |\n","-----------------------------------------\n","day: 2892, episode: 60\n","begin_total_asset: 1000000.00\n","end_total_asset: 4494765.51\n","total_reward: 3494765.51\n","total_cost: 284128.34\n","total_trades: 76115\n","Sharpe: 0.817\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 83          |\n","|    iterations           | 57          |\n","|    time_elapsed         | 1402        |\n","|    total_timesteps      | 116736      |\n","| train/                  |             |\n","|    approx_kl            | 0.028829865 |\n","|    clip_fraction        | 0.288       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.8       |\n","|    explained_variance   | 0.0953      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 19.5        |\n","|    n_updates            | 560         |\n","|    policy_gradient_loss | -0.0168     |\n","|    reward               | -0.10856376 |\n","|    std                  | 1.1         |\n","|    value_loss           | 67.5        |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 83         |\n","|    iterations           | 58         |\n","|    time_elapsed         | 1423       |\n","|    total_timesteps      | 118784     |\n","| train/                  |            |\n","|    approx_kl            | 0.02247668 |\n","|    clip_fraction        | 0.201      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -43.9      |\n","|    explained_variance   | 0.0554     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 45.7       |\n","|    n_updates            | 570        |\n","|    policy_gradient_loss | -0.00706   |\n","|    reward               | 0.8714961  |\n","|    std                  | 1.1        |\n","|    value_loss           | 107        |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 83          |\n","|    iterations           | 59          |\n","|    time_elapsed         | 1442        |\n","|    total_timesteps      | 120832      |\n","| train/                  |             |\n","|    approx_kl            | 0.016853029 |\n","|    clip_fraction        | 0.139       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.9       |\n","|    explained_variance   | 0.1         |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 56.5        |\n","|    n_updates            | 580         |\n","|    policy_gradient_loss | -0.00879    |\n","|    reward               | 1.2985169   |\n","|    std                  | 1.1         |\n","|    value_loss           | 135         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 84          |\n","|    iterations           | 60          |\n","|    time_elapsed         | 1462        |\n","|    total_timesteps      | 122880      |\n","| train/                  |             |\n","|    approx_kl            | 0.042949967 |\n","|    clip_fraction        | 0.41        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -43.9       |\n","|    explained_variance   | 0.0414      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 16          |\n","|    n_updates            | 590         |\n","|    policy_gradient_loss | -0.000374   |\n","|    reward               | -0.23635069 |\n","|    std                  | 1.1         |\n","|    value_loss           | 37.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 84          |\n","|    iterations           | 61          |\n","|    time_elapsed         | 1482        |\n","|    total_timesteps      | 124928      |\n","| train/                  |             |\n","|    approx_kl            | 0.026664628 |\n","|    clip_fraction        | 0.287       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44         |\n","|    explained_variance   | 0.0145      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 122         |\n","|    n_updates            | 600         |\n","|    policy_gradient_loss | -0.0149     |\n","|    reward               | 1.0591378   |\n","|    std                  | 1.1         |\n","|    value_loss           | 144         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 84          |\n","|    iterations           | 62          |\n","|    time_elapsed         | 1502        |\n","|    total_timesteps      | 126976      |\n","| train/                  |             |\n","|    approx_kl            | 0.044053223 |\n","|    clip_fraction        | 0.311       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44         |\n","|    explained_variance   | 0.0223      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 156         |\n","|    n_updates            | 610         |\n","|    policy_gradient_loss | 0.00201     |\n","|    reward               | 9.058733    |\n","|    std                  | 1.11        |\n","|    value_loss           | 284         |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 84         |\n","|    iterations           | 63         |\n","|    time_elapsed         | 1522       |\n","|    total_timesteps      | 129024     |\n","| train/                  |            |\n","|    approx_kl            | 0.05883839 |\n","|    clip_fraction        | 0.36       |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -44.1      |\n","|    explained_variance   | -0.000461  |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 24         |\n","|    n_updates            | 620        |\n","|    policy_gradient_loss | 0.00655    |\n","|    reward               | 3.8995821  |\n","|    std                  | 1.11       |\n","|    value_loss           | 77.4       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 84          |\n","|    iterations           | 64          |\n","|    time_elapsed         | 1542        |\n","|    total_timesteps      | 131072      |\n","| train/                  |             |\n","|    approx_kl            | 0.019093556 |\n","|    clip_fraction        | 0.155       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.2       |\n","|    explained_variance   | 0.0566      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 64.2        |\n","|    n_updates            | 630         |\n","|    policy_gradient_loss | -0.0107     |\n","|    reward               | -0.8174796  |\n","|    std                  | 1.11        |\n","|    value_loss           | 145         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 85          |\n","|    iterations           | 65          |\n","|    time_elapsed         | 1561        |\n","|    total_timesteps      | 133120      |\n","| train/                  |             |\n","|    approx_kl            | 0.020481806 |\n","|    clip_fraction        | 0.2         |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.2       |\n","|    explained_variance   | -0.0126     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 50.4        |\n","|    n_updates            | 640         |\n","|    policy_gradient_loss | -0.00825    |\n","|    reward               | -1.1908014  |\n","|    std                  | 1.11        |\n","|    value_loss           | 225         |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 85         |\n","|    iterations           | 66         |\n","|    time_elapsed         | 1580       |\n","|    total_timesteps      | 135168     |\n","| train/                  |            |\n","|    approx_kl            | 0.02802663 |\n","|    clip_fraction        | 0.244      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -44.2      |\n","|    explained_variance   | -0.0145    |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 43.2       |\n","|    n_updates            | 650        |\n","|    policy_gradient_loss | -0.00227   |\n","|    reward               | 4.9336944  |\n","|    std                  | 1.11       |\n","|    value_loss           | 173        |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 85          |\n","|    iterations           | 67          |\n","|    time_elapsed         | 1600        |\n","|    total_timesteps      | 137216      |\n","| train/                  |             |\n","|    approx_kl            | 0.053071566 |\n","|    clip_fraction        | 0.332       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.3       |\n","|    explained_variance   | 0.122       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 15          |\n","|    n_updates            | 660         |\n","|    policy_gradient_loss | 0.00298     |\n","|    reward               | -1.1408755  |\n","|    std                  | 1.12        |\n","|    value_loss           | 26.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 85          |\n","|    iterations           | 68          |\n","|    time_elapsed         | 1619        |\n","|    total_timesteps      | 139264      |\n","| train/                  |             |\n","|    approx_kl            | 0.01947501  |\n","|    clip_fraction        | 0.215       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.3       |\n","|    explained_variance   | 0.0147      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 48.1        |\n","|    n_updates            | 670         |\n","|    policy_gradient_loss | -0.0116     |\n","|    reward               | -0.80066824 |\n","|    std                  | 1.12        |\n","|    value_loss           | 118         |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 86         |\n","|    iterations           | 69         |\n","|    time_elapsed         | 1639       |\n","|    total_timesteps      | 141312     |\n","| train/                  |            |\n","|    approx_kl            | 0.04236114 |\n","|    clip_fraction        | 0.24       |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -44.4      |\n","|    explained_variance   | 0.0271     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 157        |\n","|    n_updates            | 680        |\n","|    policy_gradient_loss | -0.00609   |\n","|    reward               | -7.8399253 |\n","|    std                  | 1.12       |\n","|    value_loss           | 214        |\n","----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 86         |\n","|    iterations           | 70         |\n","|    time_elapsed         | 1658       |\n","|    total_timesteps      | 143360     |\n","| train/                  |            |\n","|    approx_kl            | 0.03590318 |\n","|    clip_fraction        | 0.295      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -44.4      |\n","|    explained_variance   | 0.0612     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 30         |\n","|    n_updates            | 690        |\n","|    policy_gradient_loss | -0.00377   |\n","|    reward               | 0.46246916 |\n","|    std                  | 1.12       |\n","|    value_loss           | 57.4       |\n","----------------------------------------\n","day: 2892, episode: 70\n","begin_total_asset: 1000000.00\n","end_total_asset: 5594586.73\n","total_reward: 4594586.73\n","total_cost: 281006.18\n","total_trades: 75601\n","Sharpe: 0.881\n","=================================\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 86          |\n","|    iterations           | 71          |\n","|    time_elapsed         | 1677        |\n","|    total_timesteps      | 145408      |\n","| train/                  |             |\n","|    approx_kl            | 0.021594882 |\n","|    clip_fraction        | 0.24        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.5       |\n","|    explained_variance   | 0.0102      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 98.6        |\n","|    n_updates            | 700         |\n","|    policy_gradient_loss | -0.00568    |\n","|    reward               | 0.26978973  |\n","|    std                  | 1.12        |\n","|    value_loss           | 138         |\n","-----------------------------------------\n","---------------------------------------\n","| time/                   |           |\n","|    fps                  | 86        |\n","|    iterations           | 72        |\n","|    time_elapsed         | 1696      |\n","|    total_timesteps      | 147456    |\n","| train/                  |           |\n","|    approx_kl            | 0.0348944 |\n","|    clip_fraction        | 0.245     |\n","|    clip_range           | 0.2       |\n","|    entropy_loss         | -44.5     |\n","|    explained_variance   | 0.0563    |\n","|    learning_rate        | 0.00025   |\n","|    loss                 | 69.6      |\n","|    n_updates            | 710       |\n","|    policy_gradient_loss | 0.00276   |\n","|    reward               | -16.09172 |\n","|    std                  | 1.12      |\n","|    value_loss           | 145       |\n","---------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 87          |\n","|    iterations           | 73          |\n","|    time_elapsed         | 1715        |\n","|    total_timesteps      | 149504      |\n","| train/                  |             |\n","|    approx_kl            | 0.051085055 |\n","|    clip_fraction        | 0.388       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.6       |\n","|    explained_variance   | 0.00493     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 45.2        |\n","|    n_updates            | 720         |\n","|    policy_gradient_loss | 0.000978    |\n","|    reward               | -1.9454879  |\n","|    std                  | 1.13        |\n","|    value_loss           | 107         |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 87         |\n","|    iterations           | 74         |\n","|    time_elapsed         | 1735       |\n","|    total_timesteps      | 151552     |\n","| train/                  |            |\n","|    approx_kl            | 0.03426893 |\n","|    clip_fraction        | 0.304      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -44.7      |\n","|    explained_variance   | 0.109      |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 22.8       |\n","|    n_updates            | 730        |\n","|    policy_gradient_loss | -0.00508   |\n","|    reward               | -1.6384522 |\n","|    std                  | 1.13       |\n","|    value_loss           | 74.2       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 87          |\n","|    iterations           | 75          |\n","|    time_elapsed         | 1761        |\n","|    total_timesteps      | 153600      |\n","| train/                  |             |\n","|    approx_kl            | 0.039675817 |\n","|    clip_fraction        | 0.289       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.7       |\n","|    explained_variance   | 0.0748      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 50.2        |\n","|    n_updates            | 740         |\n","|    policy_gradient_loss | -0.00601    |\n","|    reward               | 1.2522424   |\n","|    std                  | 1.13        |\n","|    value_loss           | 206         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 87          |\n","|    iterations           | 76          |\n","|    time_elapsed         | 1780        |\n","|    total_timesteps      | 155648      |\n","| train/                  |             |\n","|    approx_kl            | 0.033623464 |\n","|    clip_fraction        | 0.354       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.8       |\n","|    explained_variance   | 0.0205      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 82.8        |\n","|    n_updates            | 750         |\n","|    policy_gradient_loss | 0.00076     |\n","|    reward               | 0.3301079   |\n","|    std                  | 1.13        |\n","|    value_loss           | 230         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 87          |\n","|    iterations           | 77          |\n","|    time_elapsed         | 1799        |\n","|    total_timesteps      | 157696      |\n","| train/                  |             |\n","|    approx_kl            | 0.026779242 |\n","|    clip_fraction        | 0.238       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.8       |\n","|    explained_variance   | 0.19        |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 22.8        |\n","|    n_updates            | 760         |\n","|    policy_gradient_loss | -0.0035     |\n","|    reward               | 2.5910194   |\n","|    std                  | 1.14        |\n","|    value_loss           | 59.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 87          |\n","|    iterations           | 78          |\n","|    time_elapsed         | 1819        |\n","|    total_timesteps      | 159744      |\n","| train/                  |             |\n","|    approx_kl            | 0.029336544 |\n","|    clip_fraction        | 0.323       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.9       |\n","|    explained_variance   | 0.0708      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 85.6        |\n","|    n_updates            | 770         |\n","|    policy_gradient_loss | -0.00499    |\n","|    reward               | 2.3557897   |\n","|    std                  | 1.14        |\n","|    value_loss           | 208         |\n","-----------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 88           |\n","|    iterations           | 79           |\n","|    time_elapsed         | 1838         |\n","|    total_timesteps      | 161792       |\n","| train/                  |              |\n","|    approx_kl            | 0.034483384  |\n","|    clip_fraction        | 0.304        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -44.9        |\n","|    explained_variance   | 0.0663       |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 72.8         |\n","|    n_updates            | 780          |\n","|    policy_gradient_loss | 0.000709     |\n","|    reward               | -0.104663655 |\n","|    std                  | 1.14         |\n","|    value_loss           | 163          |\n","------------------------------------------\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 88           |\n","|    iterations           | 80           |\n","|    time_elapsed         | 1858         |\n","|    total_timesteps      | 163840       |\n","| train/                  |              |\n","|    approx_kl            | 0.02427899   |\n","|    clip_fraction        | 0.277        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -44.9        |\n","|    explained_variance   | 0.0416       |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 35.3         |\n","|    n_updates            | 790          |\n","|    policy_gradient_loss | -0.00437     |\n","|    reward               | -0.017846137 |\n","|    std                  | 1.14         |\n","|    value_loss           | 83.6         |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 88          |\n","|    iterations           | 81          |\n","|    time_elapsed         | 1878        |\n","|    total_timesteps      | 165888      |\n","| train/                  |             |\n","|    approx_kl            | 0.032799207 |\n","|    clip_fraction        | 0.288       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -44.9       |\n","|    explained_variance   | 0.154       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 55.8        |\n","|    n_updates            | 800         |\n","|    policy_gradient_loss | -0.00389    |\n","|    reward               | -0.48789483 |\n","|    std                  | 1.14        |\n","|    value_loss           | 84.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 88          |\n","|    iterations           | 82          |\n","|    time_elapsed         | 1896        |\n","|    total_timesteps      | 167936      |\n","| train/                  |             |\n","|    approx_kl            | 0.029400647 |\n","|    clip_fraction        | 0.273       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45         |\n","|    explained_variance   | 0.149       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 116         |\n","|    n_updates            | 810         |\n","|    policy_gradient_loss | 0.000667    |\n","|    reward               | 0.26337862  |\n","|    std                  | 1.14        |\n","|    value_loss           | 159         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 88          |\n","|    iterations           | 83          |\n","|    time_elapsed         | 1915        |\n","|    total_timesteps      | 169984      |\n","| train/                  |             |\n","|    approx_kl            | 0.024303284 |\n","|    clip_fraction        | 0.245       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45         |\n","|    explained_variance   | 0.0548      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 41.9        |\n","|    n_updates            | 820         |\n","|    policy_gradient_loss | -0.00589    |\n","|    reward               | 2.785286    |\n","|    std                  | 1.14        |\n","|    value_loss           | 110         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 88          |\n","|    iterations           | 84          |\n","|    time_elapsed         | 1934        |\n","|    total_timesteps      | 172032      |\n","| train/                  |             |\n","|    approx_kl            | 0.018797087 |\n","|    clip_fraction        | 0.185       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45         |\n","|    explained_variance   | 0.193       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 10.1        |\n","|    n_updates            | 830         |\n","|    policy_gradient_loss | -0.011      |\n","|    reward               | -0.985185   |\n","|    std                  | 1.14        |\n","|    value_loss           | 23.9        |\n","-----------------------------------------\n","day: 2892, episode: 80\n","begin_total_asset: 1000000.00\n","end_total_asset: 4772755.31\n","total_reward: 3772755.31\n","total_cost: 289663.59\n","total_trades: 75319\n","Sharpe: 0.819\n","=================================\n","------------------------------------------\n","| time/                   |              |\n","|    fps                  | 89           |\n","|    iterations           | 85           |\n","|    time_elapsed         | 1953         |\n","|    total_timesteps      | 174080       |\n","| train/                  |              |\n","|    approx_kl            | 0.021855861  |\n","|    clip_fraction        | 0.167        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -45          |\n","|    explained_variance   | 0.111        |\n","|    learning_rate        | 0.00025      |\n","|    loss                 | 24           |\n","|    n_updates            | 840          |\n","|    policy_gradient_loss | -0.00512     |\n","|    reward               | -0.027820293 |\n","|    std                  | 1.14         |\n","|    value_loss           | 90.3         |\n","------------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 89          |\n","|    iterations           | 86          |\n","|    time_elapsed         | 1972        |\n","|    total_timesteps      | 176128      |\n","| train/                  |             |\n","|    approx_kl            | 0.017737303 |\n","|    clip_fraction        | 0.221       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.1       |\n","|    explained_variance   | 0.000545    |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 67.6        |\n","|    n_updates            | 850         |\n","|    policy_gradient_loss | -0.00915    |\n","|    reward               | -1.3670607  |\n","|    std                  | 1.15        |\n","|    value_loss           | 123         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 89          |\n","|    iterations           | 87          |\n","|    time_elapsed         | 1990        |\n","|    total_timesteps      | 178176      |\n","| train/                  |             |\n","|    approx_kl            | 0.036600746 |\n","|    clip_fraction        | 0.279       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.1       |\n","|    explained_variance   | 0.151       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 16.3        |\n","|    n_updates            | 860         |\n","|    policy_gradient_loss | -0.00372    |\n","|    reward               | 3.0559165   |\n","|    std                  | 1.15        |\n","|    value_loss           | 46.1        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 89          |\n","|    iterations           | 88          |\n","|    time_elapsed         | 2008        |\n","|    total_timesteps      | 180224      |\n","| train/                  |             |\n","|    approx_kl            | 0.020640727 |\n","|    clip_fraction        | 0.194       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.1       |\n","|    explained_variance   | 0.0541      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 39.9        |\n","|    n_updates            | 870         |\n","|    policy_gradient_loss | -0.00663    |\n","|    reward               | -1.4985994  |\n","|    std                  | 1.15        |\n","|    value_loss           | 83.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 89          |\n","|    iterations           | 89          |\n","|    time_elapsed         | 2027        |\n","|    total_timesteps      | 182272      |\n","| train/                  |             |\n","|    approx_kl            | 0.030620681 |\n","|    clip_fraction        | 0.259       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.2       |\n","|    explained_variance   | 0.0722      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 45.9        |\n","|    n_updates            | 880         |\n","|    policy_gradient_loss | -0.00519    |\n","|    reward               | -0.28976518 |\n","|    std                  | 1.15        |\n","|    value_loss           | 109         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 89          |\n","|    iterations           | 90          |\n","|    time_elapsed         | 2048        |\n","|    total_timesteps      | 184320      |\n","| train/                  |             |\n","|    approx_kl            | 0.024075735 |\n","|    clip_fraction        | 0.167       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.2       |\n","|    explained_variance   | -0.0349     |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 46.6        |\n","|    n_updates            | 890         |\n","|    policy_gradient_loss | -0.00775    |\n","|    reward               | -1.3709105  |\n","|    std                  | 1.15        |\n","|    value_loss           | 111         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 90          |\n","|    iterations           | 91          |\n","|    time_elapsed         | 2067        |\n","|    total_timesteps      | 186368      |\n","| train/                  |             |\n","|    approx_kl            | 0.034600884 |\n","|    clip_fraction        | 0.346       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.2       |\n","|    explained_variance   | 0.0274      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 11.5        |\n","|    n_updates            | 900         |\n","|    policy_gradient_loss | -0.00479    |\n","|    reward               | -0.7577773  |\n","|    std                  | 1.15        |\n","|    value_loss           | 29.4        |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 90         |\n","|    iterations           | 92         |\n","|    time_elapsed         | 2085       |\n","|    total_timesteps      | 188416     |\n","| train/                  |            |\n","|    approx_kl            | 0.02805083 |\n","|    clip_fraction        | 0.23       |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -45.3      |\n","|    explained_variance   | 0.0738     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 62.6       |\n","|    n_updates            | 910        |\n","|    policy_gradient_loss | -0.00558   |\n","|    reward               | -1.4361428 |\n","|    std                  | 1.16       |\n","|    value_loss           | 96         |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 90          |\n","|    iterations           | 93          |\n","|    time_elapsed         | 2103        |\n","|    total_timesteps      | 190464      |\n","| train/                  |             |\n","|    approx_kl            | 0.030572956 |\n","|    clip_fraction        | 0.272       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.3       |\n","|    explained_variance   | 0.0527      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 51          |\n","|    n_updates            | 920         |\n","|    policy_gradient_loss | -0.00324    |\n","|    reward               | -3.0366366  |\n","|    std                  | 1.16        |\n","|    value_loss           | 161         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 90          |\n","|    iterations           | 94          |\n","|    time_elapsed         | 2121        |\n","|    total_timesteps      | 192512      |\n","| train/                  |             |\n","|    approx_kl            | 0.031282023 |\n","|    clip_fraction        | 0.219       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.4       |\n","|    explained_variance   | 0.232       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 23.8        |\n","|    n_updates            | 930         |\n","|    policy_gradient_loss | -0.00872    |\n","|    reward               | 1.2946081   |\n","|    std                  | 1.16        |\n","|    value_loss           | 50.7        |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 90          |\n","|    iterations           | 95          |\n","|    time_elapsed         | 2139        |\n","|    total_timesteps      | 194560      |\n","| train/                  |             |\n","|    approx_kl            | 0.025224615 |\n","|    clip_fraction        | 0.202       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.4       |\n","|    explained_variance   | 0.0897      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 73.6        |\n","|    n_updates            | 940         |\n","|    policy_gradient_loss | -0.0121     |\n","|    reward               | -0.39719012 |\n","|    std                  | 1.16        |\n","|    value_loss           | 142         |\n","-----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 91          |\n","|    iterations           | 96          |\n","|    time_elapsed         | 2157        |\n","|    total_timesteps      | 196608      |\n","| train/                  |             |\n","|    approx_kl            | 0.036747534 |\n","|    clip_fraction        | 0.34        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.4       |\n","|    explained_variance   | 0.0625      |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 45.4        |\n","|    n_updates            | 950         |\n","|    policy_gradient_loss | -0.00357    |\n","|    reward               | 1.0135547   |\n","|    std                  | 1.16        |\n","|    value_loss           | 171         |\n","-----------------------------------------\n","----------------------------------------\n","| time/                   |            |\n","|    fps                  | 91         |\n","|    iterations           | 97         |\n","|    time_elapsed         | 2174       |\n","|    total_timesteps      | 198656     |\n","| train/                  |            |\n","|    approx_kl            | 0.04389852 |\n","|    clip_fraction        | 0.337      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -45.5      |\n","|    explained_variance   | 0.0344     |\n","|    learning_rate        | 0.00025    |\n","|    loss                 | 33.1       |\n","|    n_updates            | 960        |\n","|    policy_gradient_loss | 0.00374    |\n","|    reward               | 0.8542724  |\n","|    std                  | 1.16       |\n","|    value_loss           | 85.6       |\n","----------------------------------------\n","-----------------------------------------\n","| time/                   |             |\n","|    fps                  | 91          |\n","|    iterations           | 98          |\n","|    time_elapsed         | 2192        |\n","|    total_timesteps      | 200704      |\n","| train/                  |             |\n","|    approx_kl            | 0.024785057 |\n","|    clip_fraction        | 0.26        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -45.6       |\n","|    explained_variance   | 0.119       |\n","|    learning_rate        | 0.00025     |\n","|    loss                 | 42.3        |\n","|    n_updates            | 970         |\n","|    policy_gradient_loss | -0.0126     |\n","|    reward               | -0.3270253  |\n","|    std                  | 1.17        |\n","|    value_loss           | 114         |\n","-----------------------------------------\n"]}],"source":["trained_ppo = agent.train_model(model=model_ppo,\n","                             tb_log_name='ppo',\n","                             total_timesteps=200000) if if_using_ppo else None"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1691998833367,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"C6AidlWyvwzm"},"outputs":[],"source":["trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None"]},{"cell_type":"markdown","metadata":{"id":"3Zpv4S0-fDBv"},"source":["### Agent 4: TD3"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1691998833367,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"JSAHhV4Xc-bh"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n","Using cpu device\n","Logging to results/td3\n"]},{"name":"stderr","output_type":"stream","text":["/Users/seanfuller/opt/anaconda3/envs/finrl/lib/python3.10/site-packages/stable_baselines3/common/buffers.py:229: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 2.45GB > 0.29GB\n","  warnings.warn(\n"]}],"source":["agent = DRLAgent(env = env_train)\n","TD3_PARAMS = {\"batch_size\": 100,\n","              \"buffer_size\": 1000000,\n","              \"learning_rate\": 0.001}\n","\n","model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n","\n","if if_using_td3:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + '/td3'\n","  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_td3.set_logger(new_logger_td3)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1691998833368,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"OSRxNYAxdKpU"},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------------------------\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 56       |\n","|    time_elapsed    | 205      |\n","|    total_timesteps | 11572    |\n","| train/             |          |\n","|    actor_loss      | 131      |\n","|    critic_loss     | 2.03e+03 |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 8679     |\n","|    reward          | 6.152368 |\n","---------------------------------\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 49       |\n","|    time_elapsed    | 464      |\n","|    total_timesteps | 23144    |\n","| train/             |          |\n","|    actor_loss      | 47.2     |\n","|    critic_loss     | 514      |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 20251    |\n","|    reward          | 6.152368 |\n","---------------------------------\n","day: 2892, episode: 100\n","begin_total_asset: 1000000.00\n","end_total_asset: 4926169.58\n","total_reward: 3926169.58\n","total_cost: 999.00\n","total_trades: 40488\n","Sharpe: 0.800\n","=================================\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 49       |\n","|    time_elapsed    | 707      |\n","|    total_timesteps | 34716    |\n","| train/             |          |\n","|    actor_loss      | 34.2     |\n","|    critic_loss     | 49.1     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 31823    |\n","|    reward          | 6.152368 |\n","---------------------------------\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 48       |\n","|    time_elapsed    | 944      |\n","|    total_timesteps | 46288    |\n","| train/             |          |\n","|    actor_loss      | 32.2     |\n","|    critic_loss     | 19.5     |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 43395    |\n","|    reward          | 6.152368 |\n","---------------------------------\n"]}],"source":["trained_td3 = agent.train_model(model=model_td3,\n","                             tb_log_name='td3',\n","                             total_timesteps=50000) if if_using_td3 else None"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1691998833368,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"OkJV6V_mv2hw"},"outputs":[],"source":["trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None"]},{"cell_type":"markdown","metadata":{"id":"Dr49PotrfG01"},"source":["### Agent 5: SAC"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1691998833368,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"xwOhVjqRkCdM"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n","Using cpu device\n","Logging to results/sac\n"]}],"source":["agent = DRLAgent(env = env_train)\n","SAC_PARAMS = {\n","    \"batch_size\": 128,\n","    \"buffer_size\": 100000,\n","    \"learning_rate\": 0.0001,\n","    \"learning_starts\": 100,\n","    \"ent_coef\": \"auto_0.1\",\n","}\n","\n","model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n","\n","if if_using_sac:\n","  # set up logger\n","  tmp_path = RESULTS_DIR + '/sac'\n","  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n","  # Set new logger\n","  model_sac.set_logger(new_logger_sac)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1691998833368,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"K8RSdKCckJyH"},"outputs":[{"name":"stdout","output_type":"stream","text":["day: 2892, episode: 110\n","begin_total_asset: 1000000.00\n","end_total_asset: 5750972.63\n","total_reward: 4750972.63\n","total_cost: 14673.96\n","total_trades: 45125\n","Sharpe: 0.930\n","=================================\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 4         |\n","|    fps             | 40        |\n","|    time_elapsed    | 285       |\n","|    total_timesteps | 11572     |\n","| train/             |           |\n","|    actor_loss      | 821       |\n","|    critic_loss     | 96.7      |\n","|    ent_coef        | 0.146     |\n","|    ent_coef_loss   | -92.5     |\n","|    learning_rate   | 0.0001    |\n","|    n_updates       | 11471     |\n","|    reward          | 3.4856157 |\n","----------------------------------\n","-----------------------------------\n","| time/              |            |\n","|    episodes        | 8          |\n","|    fps             | 40         |\n","|    time_elapsed    | 573        |\n","|    total_timesteps | 23144      |\n","| train/             |            |\n","|    actor_loss      | 369        |\n","|    critic_loss     | 49.2       |\n","|    ent_coef        | 0.0468     |\n","|    ent_coef_loss   | -129       |\n","|    learning_rate   | 0.0001     |\n","|    n_updates       | 23043      |\n","|    reward          | 12.0977955 |\n","-----------------------------------\n","day: 2892, episode: 120\n","begin_total_asset: 1000000.00\n","end_total_asset: 7179530.24\n","total_reward: 6179530.24\n","total_cost: 13511.27\n","total_trades: 53164\n","Sharpe: 0.955\n","=================================\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 12        |\n","|    fps             | 40        |\n","|    time_elapsed    | 862       |\n","|    total_timesteps | 34716     |\n","| train/             |           |\n","|    actor_loss      | 206       |\n","|    critic_loss     | 45.9      |\n","|    ent_coef        | 0.0151    |\n","|    ent_coef_loss   | -138      |\n","|    learning_rate   | 0.0001    |\n","|    n_updates       | 34615     |\n","|    reward          | 11.103959 |\n","----------------------------------\n","---------------------------------\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 39       |\n","|    time_elapsed    | 1168     |\n","|    total_timesteps | 46288    |\n","| train/             |          |\n","|    actor_loss      | 107      |\n","|    critic_loss     | 11.2     |\n","|    ent_coef        | 0.00498  |\n","|    ent_coef_loss   | -104     |\n","|    learning_rate   | 0.0001   |\n","|    n_updates       | 46187    |\n","|    reward          | 7.835206 |\n","---------------------------------\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 20        |\n","|    fps             | 39        |\n","|    time_elapsed    | 1453      |\n","|    total_timesteps | 57860     |\n","| train/             |           |\n","|    actor_loss      | 69.7      |\n","|    critic_loss     | 12.1      |\n","|    ent_coef        | 0.00175   |\n","|    ent_coef_loss   | -31.6     |\n","|    learning_rate   | 0.0001    |\n","|    n_updates       | 57759     |\n","|    reward          | 5.3435264 |\n","----------------------------------\n","day: 2892, episode: 130\n","begin_total_asset: 1000000.00\n","end_total_asset: 5863840.40\n","total_reward: 4863840.40\n","total_cost: 2297.32\n","total_trades: 43154\n","Sharpe: 0.855\n","=================================\n","----------------------------------\n","| time/              |           |\n","|    episodes        | 24        |\n","|    fps             | 39        |\n","|    time_elapsed    | 1735      |\n","|    total_timesteps | 69432     |\n","| train/             |           |\n","|    actor_loss      | 42.1      |\n","|    critic_loss     | 10.9      |\n","|    ent_coef        | 0.00113   |\n","|    ent_coef_loss   | -3.78     |\n","|    learning_rate   | 0.0001    |\n","|    n_updates       | 69331     |\n","|    reward          | 3.9945164 |\n","----------------------------------\n"]}],"source":["trained_sac = agent.train_model(model=model_sac,\n","                             tb_log_name='sac',\n","                             total_timesteps=70000) if if_using_sac else None"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1691998833368,"user":{"displayName":"Sean Fuller","userId":"01408558304609551882"},"user_tz":420},"id":"_SpZoQgPv7GO"},"outputs":[],"source":["trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"]},{"cell_type":"markdown","metadata":{"id":"PgGm3dQZfRks"},"source":["## Save the trained agent\n","Trained agents should have already been saved in the \"trained_models\" drectory after you run the code blocks above.\n","\n","For Colab users, the zip files should be at \"./trained_models\" or \"/content/trained_models\".\n","\n","For users running on your local environment, the zip files should be at \"./trained_models\"."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["MRiOtrywfAo1","_gDkU-j-fCmZ","3Zpv4S0-fDBv","Dr49PotrfG01"],"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
